{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "sz3za0AtrArP"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "VShcgv2Ca9Sp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z74w_0-8rArR"
   },
   "source": [
    "# Product_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "id": "n0moOJGmrArS",
    "outputId": "5a571fc5-e4cd-46e7-bb15-42570620ce0d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"product_df\",\n  \"rows\": 44446,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17048,\n        \"min\": 1163,\n        \"max\": 60000,\n        \"num_unique_values\": 44446,\n        \"samples\": [\n          40435,\n          18612,\n          21998\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Women\",\n          \"Unisex\",\n          \"Boys\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"masterCategory\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Apparel\",\n          \"Accessories\",\n          \"Sporting Goods\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subCategory\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 45,\n        \"samples\": [\n          \"Hair\",\n          \"Makeup\",\n          \"Free Gifts\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"articleType\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 143,\n        \"samples\": [\n          \"Hair Colour\",\n          \"Flats\",\n          \"Lip Care\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"baseColour\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 46,\n        \"samples\": [\n          \"Turquoise Blue\",\n          \"Multi\",\n          \"Magenta\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"season\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Summer\",\n          \"Spring\",\n          \"Fall\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1264014044083894,\n        \"min\": 2007.0,\n        \"max\": 2019.0,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          2009.0,\n          2019.0,\n          2011.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"usage\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Ethnic\",\n          \"Travel\",\n          \"Casual\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"productDisplayName\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 31135,\n        \"samples\": [\n          \"Nike Women White Air Dictate MSL Sports Shoes\",\n          \"Ivory Tag Women Rock Array Blue and Red Jewellery Set\",\n          \"Femella Women Pink T-shirt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"combined_info\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33268,\n        \"samples\": [\n          \"Product Name: Biotique Bio Cucumber Pore Tightening Freshener, Gender: Women, Master Category: Personal Care, Sub Category: Skin Care, Article Type: Toner, Base Colour: Green, Season: Spring,Usage: nan\",\n          \"Product Name: Tantra Men's Autorikshaw White T-shirt, Gender: Men, Master Category: Apparel, Sub Category: Topwear, Article Type: Tshirts, Base Colour: White, Season: Summer,Usage: Casual\",\n          \"Product Name: Deborah Atomic Red 12 Lipstick, Gender: Women, Master Category: Personal Care, Sub Category: Lips, Article Type: Lipstick, Base Colour: Red, Season: Spring,Usage: nan\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embeddings\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33078,\n        \"samples\": [\n          \"[-2.41286028e-02  3.15715335e-02 -3.19219157e-02 -3.22608240e-02\\n -8.57862644e-03 -3.24990004e-02  7.93237090e-02  7.46822543e-03\\n -9.25778151e-02  2.06728838e-03  1.75309889e-02 -4.72787693e-02\\n -1.76966179e-03 -3.02650947e-02 -1.67535320e-02  9.22048762e-02\\n  2.69558784e-02  6.40072301e-02  4.21432741e-02 -3.49986702e-02\\n  6.66242540e-02 -6.71069976e-03 -5.71577214e-02  4.37476598e-02\\n -1.45428658e-01  2.13748608e-02 -2.88170995e-03  3.34557705e-02\\n -4.14207876e-02 -9.68579352e-02 -2.19642371e-02  5.45235574e-02\\n  1.63505629e-01  7.84740448e-02 -1.39211625e-04 -6.10179938e-02\\n -3.29432301e-02 -4.89519536e-02 -4.63591926e-02  4.35146727e-02\\n  2.07265429e-02 -1.13310367e-01 -8.24389011e-02  1.73359346e-02\\n  2.99354251e-02  3.76843214e-02  1.34531315e-02  3.36951464e-02\\n -5.14755696e-02  1.33088559e-01 -6.38432428e-02 -7.73763563e-03\\n -2.89206076e-02 -6.40267390e-04  4.66076322e-02 -4.35694531e-02\\n -6.23485446e-02 -1.34613318e-02 -8.63358285e-03 -4.28458489e-02\\n  6.20850399e-02  2.56941728e-02 -1.16193518e-01  6.30875770e-03\\n  4.33924375e-04 -4.53584306e-02  1.98207814e-02  2.26689056e-02\\n -3.64847220e-02 -1.33158434e-02  1.07828371e-01 -1.73888952e-02\\n  9.24152881e-03  3.74463224e-03 -8.61289427e-02  7.68160820e-02\\n  5.52364551e-02 -7.50076100e-02 -5.04955240e-02 -8.99400655e-03\\n -8.12551752e-02  1.11762229e-02 -3.35403555e-03 -1.32255256e-03\\n -7.62883155e-03  3.02596483e-02 -1.83445252e-02 -3.45628224e-02\\n -6.90418705e-02 -1.68663301e-02 -1.19350366e-01  5.93979703e-03\\n  1.19030187e-02  5.57292486e-04 -8.70339293e-03  3.17022242e-02\\n  2.90111247e-02 -1.20228517e-03  2.17605531e-02  3.56981158e-02\\n  9.83840879e-03  3.72201651e-02  4.30674292e-02 -4.96255271e-02\\n -9.15327221e-02 -6.82240427e-02  2.44734176e-02  6.17807135e-02\\n  5.90212904e-02  7.94680417e-02 -9.51047540e-02 -1.86415091e-02\\n -1.51792824e-01 -3.86563614e-02 -7.25327507e-02 -5.46270460e-02\\n  1.37092341e-02 -3.89822829e-03  7.93474019e-02  2.07616445e-02\\n -2.05919147e-02  3.06935050e-02  1.51917823e-02 -2.22155545e-02\\n -8.48374143e-02 -2.17983950e-04  2.26107463e-02  1.37902879e-35\\n -9.08591449e-02 -3.11688539e-02  1.27848573e-02  3.20746750e-02\\n -2.55517773e-02  1.60134081e-02 -1.09780272e-02 -8.72583613e-02\\n -4.82525006e-02 -5.06860800e-02 -4.10695486e-02  9.16722640e-02\\n -6.91853911e-02  2.50947922e-02  1.18136983e-02 -2.79169828e-02\\n  4.55383062e-02 -1.63176525e-02 -2.40614936e-02 -3.39359674e-03\\n  1.52455559e-02  9.13973525e-02 -7.78158382e-02  4.56659757e-02\\n  2.93917116e-02 -1.14636999e-02  6.00536503e-02 -1.68070402e-02\\n  1.17758652e-02  2.62487531e-02  6.48970455e-02  6.34064618e-03\\n  5.24804853e-02 -9.62810218e-02 -5.44027425e-02  9.05443099e-04\\n  8.37992597e-03  3.28417905e-02 -5.82222044e-02  2.47783307e-02\\n  7.21389800e-02 -9.16021466e-02 -6.12657890e-02  3.03040165e-02\\n  8.39304179e-03  6.65551936e-03 -9.80555173e-03  1.18966484e-02\\n  2.05359869e-02 -1.88148692e-02 -6.03721179e-02  1.78351253e-02\\n  1.08766202e-02 -7.05151185e-02 -4.10563871e-03 -7.80300722e-02\\n -4.98599326e-03  2.02317089e-02 -3.07465307e-02  2.02991930e-03\\n -3.73979285e-02  5.49309142e-02  2.15371177e-02 -2.40109279e-03\\n -5.81805706e-02 -1.24432735e-01  2.53365971e-02  2.40839589e-02\\n  3.87865235e-03  4.98914532e-02 -2.21386459e-02  1.93214025e-02\\n  4.23849486e-02  8.76781419e-02  1.84825398e-02  4.16499242e-05\\n -1.12920236e-02  7.88264796e-02 -2.93113776e-02  3.66336964e-02\\n -5.04615791e-02 -1.04069281e-02  5.36090955e-02 -2.29667104e-03\\n -3.39610502e-02  1.12380814e-02  4.17692820e-04 -1.70990149e-03\\n -4.35144305e-02  1.22656887e-02 -7.35669434e-02  9.13561955e-02\\n -4.40529324e-02  4.92296033e-02 -8.34053010e-03 -4.65168314e-33\\n  4.74131890e-02 -6.07327484e-02  4.20378447e-02  9.81787071e-02\\n  8.50519761e-02  6.16685674e-02 -4.27724514e-03  3.01004611e-02\\n  7.01303706e-02  7.99168870e-02  4.59423549e-02 -4.62970845e-02\\n  7.30029400e-03  9.96780582e-03  4.53968495e-02  4.47401404e-02\\n  1.53796514e-02  7.33422115e-02 -7.99745023e-02  4.04135995e-02\\n -4.11885306e-02  9.20912772e-02  4.51039150e-02 -1.58852432e-02\\n -9.60099995e-02 -2.60117883e-03  1.10922270e-01 -1.41335549e-02\\n -1.15760028e-01  5.54000847e-02  1.51912831e-02 -6.38298541e-02\\n -9.56151262e-03  1.18988432e-01 -6.14055544e-02 -7.89731443e-02\\n -5.07332012e-02  2.46144347e-02  3.49198841e-03 -1.38514917e-02\\n  4.30346932e-03  2.06745870e-04 -3.88957299e-02 -1.22257266e-02\\n -3.16013433e-02 -1.19974382e-01  9.04355943e-03 -3.30345221e-02\\n  3.95477600e-02 -6.16588369e-02  4.67410013e-02  1.65302530e-02\\n -2.17178334e-02 -4.29381095e-02 -2.25302810e-03 -1.12676611e-02\\n -9.25858170e-02 -4.97366127e-04 -3.34674492e-02  7.19256252e-02\\n  8.12967680e-03  3.91629972e-02 -5.47410212e-02 -2.95486320e-02\\n  5.74760623e-02 -6.84997216e-02 -2.33606361e-02 -3.52598689e-02\\n -3.04302592e-02 -7.64827132e-02  2.42472049e-02  1.70527883e-02\\n -2.00241171e-02  9.62127596e-02  1.28732985e-02  2.64052376e-02\\n -4.02657650e-02  7.79865831e-02  4.73341811e-03 -1.27418078e-02\\n  1.44436536e-02 -3.22401039e-02 -2.63377558e-02  9.29758325e-02\\n  7.51342671e-03  6.05898649e-02 -3.41637700e-04  7.73128867e-02\\n  1.98086333e-02 -2.67747398e-02  3.74422595e-03  6.03561141e-02\\n -4.98398058e-02  6.11949712e-02 -3.74509282e-02 -3.12093036e-08\\n  8.86329636e-02  1.32123400e-02 -1.76876001e-02  8.47012475e-02\\n  2.48237886e-03  6.37481734e-03 -5.17494082e-02 -5.33536747e-02\\n  9.33310166e-02  2.84120683e-02 -2.07176004e-02  8.72214697e-03\\n -3.23596857e-02  5.22146150e-02  3.60881984e-02 -3.59045062e-03\\n -4.03867215e-02  2.91349180e-02  4.80471067e-02  1.21423545e-04\\n -2.74552386e-02 -3.17361318e-02  4.63853329e-02  5.88028654e-02\\n -5.14995940e-02 -4.38950583e-02 -2.78205462e-02 -6.21329360e-02\\n  1.38823567e-02 -1.79043543e-02  2.04655584e-02  2.28986945e-02\\n -8.53991788e-03 -1.94566585e-02  3.59399095e-02  4.25455570e-02\\n  8.77890140e-02  1.60927791e-02 -6.31330013e-02  4.48050722e-02\\n -1.60054453e-02 -1.58500910e-01  6.45391494e-02 -3.33637595e-02\\n -9.69218463e-02 -2.04869695e-02  2.74707712e-02  6.58008158e-02\\n -7.42487982e-02  2.47304477e-02 -3.83541659e-02  1.09965848e-02\\n  1.75521299e-02 -4.39866520e-02 -3.38616706e-02 -2.66248547e-02\\n  2.55359057e-02 -9.23456065e-03  6.04442600e-03 -6.68847188e-02\\n  1.25751957e-01 -4.18049842e-02 -5.25880679e-02  6.47407994e-02]\",\n          \"[-5.10554947e-02  5.08125909e-02  1.15040345e-02 -4.49468270e-02\\n  8.22427794e-02 -4.42273691e-02  1.57299519e-01 -5.19778254e-03\\n -3.41802910e-02 -3.38473059e-02  3.01844683e-02 -1.04784168e-01\\n  2.31757350e-02 -1.63823105e-02  6.94144815e-02  1.66281983e-02\\n  3.84525806e-02  3.08685079e-02  3.66686867e-03 -8.37881863e-02\\n  3.27620320e-02  5.83030730e-02  8.58848915e-03  5.19487588e-03\\n -1.72417253e-01 -4.22347188e-02 -4.13780920e-02  6.61314428e-02\\n  2.98702973e-03 -5.61250597e-02 -2.77834758e-02  1.20569423e-01\\n  1.31514460e-01  6.08431436e-02 -3.00044175e-02 -1.43804708e-02\\n -3.30817682e-04 -8.32852796e-02 -8.91441777e-02  8.10266286e-02\\n -4.20608968e-02 -7.78167099e-02 -9.45441425e-02  5.92647642e-02\\n  3.05450037e-02  5.28802015e-02 -4.99466388e-03  6.14341348e-02\\n -5.81887811e-02  6.30022883e-02 -6.09641224e-02 -8.69480968e-02\\n -3.02433074e-02  4.22806442e-02  9.94534604e-03  3.97687033e-02\\n -2.66773179e-02 -2.86141876e-02 -5.61974524e-03 -2.15550885e-02\\n  3.05933077e-02 -3.39585543e-02 -6.49359301e-02  4.46996801e-02\\n  4.96052392e-03  8.47548526e-03  1.02808261e-02  5.42613901e-02\\n -4.73558493e-02 -2.50930022e-02  1.90685727e-02 -5.22311497e-03\\n  2.01908238e-02  1.03296272e-01 -4.51199077e-02  3.26199979e-02\\n  9.45300683e-02 -4.36595418e-02 -5.13046794e-02 -1.20205013e-02\\n -1.01482935e-01  2.05620658e-02 -3.51117216e-02 -3.59874107e-02\\n  3.74722332e-02  3.26443501e-02 -6.46341592e-02  2.13973597e-03\\n -9.21920538e-02 -1.51380412e-02 -1.40857548e-01  2.64668632e-02\\n  3.08972970e-02 -5.45941405e-02 -7.30533302e-02 -4.75345086e-03\\n -1.52274026e-02 -1.33966357e-02 -3.66782025e-02  7.10926056e-02\\n -2.15151440e-03 -2.74526626e-02  2.11747903e-02 -4.71796319e-02\\n -1.38442770e-01 -4.95704003e-02 -3.96212190e-02  7.97074214e-02\\n  7.77252465e-02  7.47805536e-02 -7.77636543e-02 -1.07945250e-02\\n -1.11538723e-01 -5.65908886e-02 -4.31845039e-02 -4.48073409e-02\\n  1.39595503e-02  3.59572582e-02  5.45902327e-02 -2.38921307e-03\\n  1.95448138e-02 -1.71974339e-02 -1.89694092e-02 -5.00130653e-02\\n -1.24600664e-01  2.17103884e-02  6.17426299e-02  6.21641086e-34\\n  2.30809171e-02  2.61499342e-02  2.14469805e-03  8.15333575e-02\\n  2.62041967e-02  4.37947502e-03  3.39937769e-02 -5.35828061e-02\\n -3.04762721e-02 -4.17393185e-02  3.44744809e-02  5.21184467e-02\\n -1.07206486e-01  5.78610748e-02  5.43562919e-02  3.65785323e-02\\n  2.12274902e-02 -1.63925868e-02 -9.08968970e-02 -2.31075361e-02\\n  5.68146119e-04  7.82386214e-02 -4.95861284e-03  4.11573164e-02\\n  4.39601541e-02 -4.91749011e-02  5.10366969e-02 -7.03324005e-02\\n  3.34826075e-02  1.34504605e-02  6.46464154e-02 -7.27244932e-03\\n  9.65647325e-02 -2.51346007e-02 -2.64607072e-02  8.07834975e-03\\n -8.45544599e-03  9.15137213e-03  2.00015623e-02  8.78538787e-02\\n  5.20864986e-02 -3.60094383e-02 -2.29509138e-02  3.66390347e-02\\n  5.40857855e-03 -6.25939481e-03  5.41011952e-02 -1.23145999e-02\\n  1.14247864e-02 -2.99160630e-02 -5.47688045e-02 -2.82416455e-02\\n -8.09918121e-02 -6.77372813e-02  7.89673347e-03 -5.04461639e-02\\n -1.39995487e-02  4.82142605e-02 -6.69751018e-02 -7.67099932e-02\\n -3.11841853e-02 -2.82816682e-03  5.75891696e-02 -1.93279684e-02\\n -5.71687929e-02 -1.10941917e-01 -3.84834483e-02 -3.73292342e-02\\n -1.71798710e-02  1.87071655e-02 -1.75184160e-02  3.51938739e-04\\n  2.39868164e-02  5.83609864e-02  8.03514719e-02  2.18145698e-02\\n  1.82998851e-02  2.13505756e-02 -1.14846518e-02  4.76200096e-02\\n -3.45153436e-02  5.17967064e-03 -1.96252633e-02  3.93324792e-02\\n -5.04253507e-02 -1.42062409e-02  5.30207306e-02 -3.28433812e-02\\n  3.79991606e-02 -2.24084351e-02 -7.65901729e-02  6.98200613e-02\\n -6.40885625e-03  3.56186926e-02 -4.06108685e-02 -4.25797115e-33\\n  3.29047479e-02  1.92950368e-02  5.28649054e-03  5.76769151e-02\\n  7.31618106e-02 -9.44618974e-03  8.71543959e-03  7.89278522e-02\\n -4.12881887e-03  5.15202545e-02  7.62221217e-02 -3.19291279e-02\\n -8.06375816e-02  3.90346386e-02  8.65107998e-02  4.64364327e-02\\n  7.49906898e-02  7.91267455e-02 -3.05415541e-02  4.01850268e-02\\n -2.47690510e-02  2.11127778e-03  1.13927312e-02 -2.98974440e-02\\n -4.07574326e-02 -1.17801744e-02  2.20749006e-02  1.30982120e-02\\n -1.70867257e-02 -2.86346059e-02 -5.56179434e-02 -2.16226354e-02\\n -3.55649032e-02  1.49414971e-01 -7.50716589e-03 -5.11680692e-02\\n  2.68540811e-02 -1.27107808e-02  8.88621807e-03  3.11651882e-02\\n  4.54691704e-03  2.56615062e-03  8.69429205e-03 -1.45110616e-03\\n -1.09331228e-01 -1.52445585e-01 -5.39544895e-02 -1.19911663e-01\\n -2.54596565e-02 -3.01926229e-02  5.01644313e-02  2.63524596e-02\\n -5.38648888e-02 -6.24476746e-02 -1.12834414e-02  5.82331046e-03\\n -2.41557211e-02 -9.32185911e-03 -3.45676653e-02  8.07018578e-03\\n  2.23212428e-02  4.39715832e-02 -6.82637990e-02 -1.66058335e-02\\n  5.95600717e-02 -1.38728302e-02 -4.02666330e-02  7.40088872e-04\\n  2.16740230e-03 -5.13038412e-02 -6.30329503e-03 -3.84115353e-02\\n  4.23355354e-03 -6.30924618e-03 -5.74224442e-02 -5.84317520e-02\\n -4.53876369e-02  3.56437340e-02 -4.39355187e-02  2.62491982e-02\\n  3.16305347e-02  6.13598060e-03 -8.16033408e-03  6.68843165e-02\\n  2.53159627e-02  6.95773661e-02 -1.99722312e-02  1.48172677e-01\\n  8.59068260e-02 -9.60155297e-03 -9.85049363e-03  5.93270808e-02\\n -1.50934709e-02  1.39433101e-01  2.81805918e-02 -3.72270392e-08\\n  3.17471065e-02 -9.86801907e-02  1.92790646e-02  6.26553744e-02\\n -6.27588015e-03 -2.62757987e-02 -4.65509184e-02 -9.31459069e-02\\n  4.98946086e-02  8.73663183e-03 -2.35196464e-02  3.75233628e-02\\n -4.96413223e-02  1.41436197e-02  3.82863358e-02 -4.57331119e-03\\n -7.02865049e-02  3.38173807e-02  3.43917608e-02 -5.03465123e-02\\n -3.45714414e-03  2.52641067e-02  6.10593054e-03  1.26784101e-01\\n -2.52654795e-02  1.06369015e-02 -2.68277600e-02  6.34781364e-03\\n  1.18922209e-02 -3.60105410e-02 -2.98835672e-02  4.94794995e-02\\n -2.43860316e-02 -1.00388546e-02 -1.88436285e-02 -3.84519212e-02\\n  1.61895379e-02  2.57698577e-02 -4.12076042e-05  2.38360539e-02\\n  2.78710648e-02 -7.31801167e-02  3.78252976e-02  4.41247597e-02\\n  2.88018174e-02 -5.42770550e-02 -4.88305613e-02  2.55253026e-03\\n -2.41861567e-02 -1.34170000e-02 -4.70990092e-02 -9.79038049e-03\\n  9.92238801e-03  5.51454984e-02 -4.26365249e-02 -6.13803975e-02\\n  3.89915123e-03 -7.71964784e-04  1.90754924e-02 -8.85394514e-02\\n  4.50709611e-02 -1.53872734e-02 -6.55694082e-02 -8.75959732e-03]\",\n          \"[-4.36487570e-02 -1.89621989e-02  2.19048876e-02 -9.11851786e-03\\n  8.56721215e-03 -7.02385977e-02  1.15141109e-01  1.91895273e-02\\n -8.42891559e-02 -5.21835219e-03 -6.68683555e-03 -1.01990700e-01\\n  5.88604398e-02 -5.96704744e-02 -3.47128697e-02  6.46389127e-02\\n  1.30912110e-01 -8.07269756e-03 -4.62325513e-02 -1.04897052e-01\\n -2.27966588e-02 -4.26817052e-02 -6.32205382e-02  4.97440323e-02\\n -1.01797260e-01  2.17465553e-02 -9.60145220e-02  1.70235503e-02\\n -7.39340261e-02 -6.09582253e-02 -2.76661646e-02  3.21576110e-04\\n  4.94975820e-02  5.22279032e-02 -3.32113728e-02 -6.70750588e-02\\n -8.63833651e-02 -7.97758475e-02 -4.95025516e-02 -1.12629533e-02\\n  4.18219110e-03 -8.65755528e-02 -1.02035671e-01  7.01284632e-02\\n -3.53873223e-02  7.80768320e-02  3.56809609e-02  7.45980442e-02\\n -3.38045992e-02  7.27711022e-02 -3.42189893e-02 -8.68819132e-02\\n -1.65612809e-02  4.60842811e-02  2.05643214e-02  1.81268025e-02\\n -6.62845001e-02 -2.45919861e-02  1.68512333e-02  6.41499683e-02\\n  6.78198338e-02  4.35073413e-02 -7.89287388e-02 -8.94827861e-03\\n  4.57377732e-02 -1.16108293e-02  3.05416770e-02  1.16588235e-01\\n -6.43857419e-02  3.05754133e-02  6.71807453e-02  4.42696698e-02\\n -2.59087328e-02  6.28376976e-02  2.32543405e-02  2.11536773e-02\\n  8.22024643e-02 -1.20024435e-01 -5.02246898e-03  2.72546150e-02\\n -1.41102523e-01  2.44683716e-02  5.62894754e-02  1.03409495e-02\\n -4.44593914e-02 -4.78290692e-02 -3.14369872e-02 -3.15070152e-02\\n -2.82335412e-02 -2.26446744e-02 -1.04493715e-01  6.52813539e-03\\n  7.30971014e-03 -3.65397222e-02 -6.35375455e-02 -9.28254973e-04\\n -1.72938555e-02 -2.16430519e-02 -7.87163898e-03  8.26554596e-02\\n -5.13778068e-02  4.17876579e-02  8.65173861e-02 -2.52780151e-02\\n -7.42571279e-02 -4.22565416e-02  1.85116509e-03  4.12096195e-02\\n  5.53159714e-02 -3.19928750e-02 -3.80287208e-02  7.37181772e-03\\n -9.96606499e-02 -1.92279909e-02  7.01515526e-02 -1.00015394e-01\\n  2.15397589e-02  7.60062858e-02  1.10271588e-01 -7.43199289e-02\\n  5.48128374e-02  4.06260416e-02  6.12457842e-02 -7.37017673e-03\\n -1.37528643e-01 -5.58835315e-03  4.12810035e-02  8.79499639e-34\\n  1.93856899e-02  2.22230479e-02  3.24274786e-02  8.30270424e-02\\n  1.99390631e-02  9.23942216e-03 -1.51924146e-02 -4.97199781e-02\\n -5.52846231e-02  1.65783074e-02 -8.91763344e-03  2.74642780e-02\\n -1.20454580e-01 -3.55941150e-03  1.28565982e-01  6.71234801e-02\\n  9.19057876e-02  5.84293250e-03 -3.04851774e-02 -2.74610966e-02\\n  2.58088335e-02  5.11980355e-02 -9.27931145e-02  2.02838555e-02\\n -3.60669345e-02 -7.98685625e-02  3.64498235e-02 -1.19040320e-02\\n  3.43193561e-02  7.85063859e-03  3.09855770e-02 -3.16678397e-02\\n  9.24830586e-02 -8.93271901e-03 -4.72851954e-02 -2.73368880e-02\\n  2.72779204e-02 -1.21481502e-02  3.09356973e-02  5.01704682e-03\\n  5.51989451e-02 -5.52697061e-03  1.16458191e-02  4.45223451e-02\\n -5.57278320e-02  5.15416972e-02  2.09375825e-02 -2.18279753e-02\\n  3.56179774e-02 -2.04745121e-02 -4.30528484e-02 -3.40240709e-02\\n  5.26263863e-02 -1.92487612e-02 -4.12067696e-02 -7.47808302e-03\\n -3.15534137e-02  1.15217259e-02  6.04593307e-02  4.09489078e-03\\n -3.41706700e-03 -2.01722737e-02  5.60093597e-02 -7.61262700e-02\\n -9.67546657e-05 -6.89714849e-02  4.93212231e-02  2.31695315e-03\\n -1.86253544e-02  6.87269419e-02 -6.97209612e-02  1.14623539e-01\\n  1.20094866e-02 -8.35809112e-03  3.91640291e-02  3.74589339e-02\\n  6.73047733e-03 -1.06966859e-02  2.93151792e-02 -3.14649977e-02\\n -4.69685867e-02 -1.13670928e-02 -4.01629731e-02 -2.95152632e-03\\n -5.87614737e-02  6.79782312e-03 -2.24180836e-02 -8.03828388e-02\\n -2.16565747e-03  3.55862044e-02 -4.92438711e-02  2.40368973e-02\\n  1.34670744e-02  5.25925532e-02 -7.02656880e-02 -2.89063997e-33\\n  2.94174161e-02 -3.79558802e-02  3.74992937e-02  2.85387747e-02\\n  6.89806417e-02  2.55160108e-02 -1.98692102e-02  5.30529022e-02\\n -4.49544042e-02  7.12842196e-02  1.10463448e-01 -7.03512728e-02\\n -6.95691630e-02  5.53859212e-02  5.85299581e-02  1.93505660e-02\\n  5.68471737e-02  4.38071154e-02 -6.77962229e-02 -2.90290620e-02\\n -5.35697043e-02  7.20805898e-02  1.18815312e-02  1.62748564e-02\\n -7.28652328e-02 -1.89648233e-02  5.27206734e-02 -8.93354323e-03\\n  2.74303332e-02  1.27325701e-02  6.59477245e-03 -1.88150140e-03\\n -2.51598097e-03  5.07474542e-02  1.23710586e-02 -3.84529866e-03\\n  4.12124116e-03 -1.52377244e-02  4.28721197e-02 -5.93796037e-02\\n -1.48624256e-02 -4.26703785e-03  3.64328846e-02  5.43021001e-02\\n -5.25008067e-02 -5.54365106e-02 -3.54364291e-02 -5.67318462e-02\\n  7.44929388e-02 -4.67744432e-02  2.78544724e-02 -2.61904746e-02\\n -5.30053712e-02  4.26240042e-02 -2.32545435e-02 -5.86984232e-02\\n -2.05879845e-02  7.40390345e-02  8.63550324e-03  2.43907291e-02\\n -2.34174859e-02 -1.30137866e-02 -3.17202024e-02 -6.29907995e-02\\n  5.67405066e-03 -3.43099236e-02 -4.34877984e-02 -5.05351424e-02\\n -1.04581583e-02  9.32765566e-03 -6.28416389e-02 -8.24630726e-03\\n -5.79484031e-02 -3.22002657e-02 -1.60895754e-02 -1.03084773e-01\\n  5.67416213e-02  6.37905151e-02 -2.38640490e-03  2.54581030e-03\\n  2.95527652e-02  3.86977009e-02  2.94526704e-02  1.83126256e-02\\n  6.24962859e-02  3.70491110e-02  4.22653146e-02  1.37900606e-01\\n  4.31853123e-02 -9.40816384e-03 -2.47700047e-02 -2.18036994e-02\\n -4.85769734e-02  3.56829315e-02 -4.12858054e-02 -3.32496128e-08\\n -1.57053433e-02 -5.32712461e-03  1.18752196e-02  5.03077209e-02\\n  1.78816933e-02  8.78925174e-02  1.88555080e-03 -9.98438150e-03\\n  3.06317993e-02  4.63192118e-03  3.41161829e-03 -5.28560439e-03\\n -2.13803127e-02 -6.17407728e-03 -3.53358425e-02 -2.00740118e-02\\n -3.89068462e-02  4.90712225e-02  8.50135833e-02 -2.40299925e-02\\n  1.71621442e-02 -2.86235064e-02  3.72049958e-02  2.04258338e-02\\n -4.42423783e-02  3.84207279e-03 -5.59403040e-02 -4.63093184e-02\\n -1.34335756e-02  7.37081791e-05  4.94201817e-02  6.28757011e-03\\n  2.28890534e-02 -2.10075565e-02  8.19233283e-02  2.63313074e-02\\n -1.52254812e-02  2.53695622e-02 -3.54112089e-02 -2.88825128e-02\\n -2.73672901e-02 -1.09012619e-01  2.92229131e-02  4.80765365e-02\\n  3.27820927e-02 -4.80394019e-03  4.30332236e-02  3.40675376e-02\\n -3.59009579e-02  1.95657238e-02 -5.32488301e-02 -8.74565691e-02\\n  5.01080938e-02  4.55807112e-02 -8.22506174e-02 -5.66416346e-02\\n  4.25266437e-02  4.83656488e-02  2.27466058e-02  2.91618332e-02\\n  1.75408140e-01 -1.03442408e-01 -1.08275265e-01  5.72455935e-02]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "product_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-a07ee347-4edd-4cad-8bb0-99e9aeb30523\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>masterCategory</th>\n",
       "      <th>subCategory</th>\n",
       "      <th>articleType</th>\n",
       "      <th>baseColour</th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>usage</th>\n",
       "      <th>productDisplayName</th>\n",
       "      <th>combined_info</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15970</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Shirts</td>\n",
       "      <td>Navy Blue</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Turtle Check Men Navy Blue Shirt</td>\n",
       "      <td>Product Name: Turtle Check Men Navy Blue Shirt...</td>\n",
       "      <td>[-2.68268585e-02  6.60445839e-02  1.56628564e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39386</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Jeans</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Peter England Men Party Blue Jeans</td>\n",
       "      <td>Product Name: Peter England Men Party Blue Jea...</td>\n",
       "      <td>[-3.63447741e-02 -1.79072991e-02  1.01005035e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59263</td>\n",
       "      <td>Women</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Watches</td>\n",
       "      <td>Watches</td>\n",
       "      <td>Silver</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Titan Women Silver Watch</td>\n",
       "      <td>Product Name: Titan Women Silver Watch, Gender...</td>\n",
       "      <td>[-8.63776952e-02 -4.10641469e-02  3.33572179e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21379</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Track Pants</td>\n",
       "      <td>Black</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Manchester United Men Solid Black Track Pants</td>\n",
       "      <td>Product Name: Manchester United Men Solid Blac...</td>\n",
       "      <td>[-4.90391180e-02 -1.59678720e-02 -3.54683548e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53759</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Tshirts</td>\n",
       "      <td>Grey</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Puma Men Grey T-shirt</td>\n",
       "      <td>Product Name: Puma Men Grey T-shirt, Gender: M...</td>\n",
       "      <td>[-2.36744732e-02  4.10940349e-02 -2.29127221e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a07ee347-4edd-4cad-8bb0-99e9aeb30523')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-a07ee347-4edd-4cad-8bb0-99e9aeb30523 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-a07ee347-4edd-4cad-8bb0-99e9aeb30523');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-e71fd543-e936-4e48-a3fb-e36f9a30fce5\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e71fd543-e936-4e48-a3fb-e36f9a30fce5')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-e71fd543-e936-4e48-a3fb-e36f9a30fce5 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "      id gender masterCategory subCategory  articleType baseColour  season  \\\n",
       "0  15970    Men        Apparel     Topwear       Shirts  Navy Blue    Fall   \n",
       "1  39386    Men        Apparel  Bottomwear        Jeans       Blue  Summer   \n",
       "2  59263  Women    Accessories     Watches      Watches     Silver  Winter   \n",
       "3  21379    Men        Apparel  Bottomwear  Track Pants      Black    Fall   \n",
       "4  53759    Men        Apparel     Topwear      Tshirts       Grey  Summer   \n",
       "\n",
       "     year   usage                             productDisplayName  \\\n",
       "0  2011.0  Casual               Turtle Check Men Navy Blue Shirt   \n",
       "1  2012.0  Casual             Peter England Men Party Blue Jeans   \n",
       "2  2016.0  Casual                       Titan Women Silver Watch   \n",
       "3  2011.0  Casual  Manchester United Men Solid Black Track Pants   \n",
       "4  2012.0  Casual                          Puma Men Grey T-shirt   \n",
       "\n",
       "                                       combined_info  \\\n",
       "0  Product Name: Turtle Check Men Navy Blue Shirt...   \n",
       "1  Product Name: Peter England Men Party Blue Jea...   \n",
       "2  Product Name: Titan Women Silver Watch, Gender...   \n",
       "3  Product Name: Manchester United Men Solid Blac...   \n",
       "4  Product Name: Puma Men Grey T-shirt, Gender: M...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-2.68268585e-02  6.60445839e-02  1.56628564e-...  \n",
       "1  [-3.63447741e-02 -1.79072991e-02  1.01005035e-...  \n",
       "2  [-8.63776952e-02 -4.10641469e-02  3.33572179e-...  \n",
       "3  [-4.90391180e-02 -1.59678720e-02 -3.54683548e-...  \n",
       "4  [-2.36744732e-02  4.10940349e-02 -2.29127221e-...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_df = pd.read_csv('processed_product_final.csv')\n",
    "product_df = product_df.iloc[: , 1:]\n",
    "product_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "km0Gvst-L3Bx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Gc3pvikrArS",
    "outputId": "0419a0b1-19c9-432d-f073-70e8704b225e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44446 entries, 0 to 44445\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   id                  44446 non-null  int64  \n",
      " 1   gender              44446 non-null  object \n",
      " 2   masterCategory      44446 non-null  object \n",
      " 3   subCategory         44446 non-null  object \n",
      " 4   articleType         44446 non-null  object \n",
      " 5   baseColour          44431 non-null  object \n",
      " 6   season              44425 non-null  object \n",
      " 7   year                44445 non-null  float64\n",
      " 8   usage               44129 non-null  object \n",
      " 9   productDisplayName  44439 non-null  object \n",
      " 10  combined_info       44446 non-null  object \n",
      " 11  embeddings          44446 non-null  object \n",
      "dtypes: float64(1), int64(1), object(10)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "product_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "y8VoSTDarArT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "E1PLxVNurArT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "4XwGe3rTrArT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "UiFnS8hrrArT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVJGGcBdrCp1"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwnvC8bErArU"
   },
   "source": [
    "# Customer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "5Z6cnSKNrArU",
    "outputId": "b3032d34-ab36-454b-b5f2-fd31139efe02"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"customer_df\",\n  \"rows\": 100000,\n  \"fields\": [\n    {\n      \"column\": \"customer_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28867,\n        \"min\": 1,\n        \"max\": 100000,\n        \"num_unique_values\": 100000,\n        \"samples\": [\n          93539,\n          56643,\n          70967\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"first_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 707,\n        \"samples\": [\n          \"Gangsar\",\n          \"Umaya\",\n          \"Hairyanto\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"last_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 173,\n        \"samples\": [\n          \"Maryadi\",\n          \"Rajasa\",\n          \"Anggraini\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"username\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100000,\n        \"samples\": [\n          \"13668e05-dc59-4508-8175-6cb5a34f6d9c\",\n          \"02814af4-c418-4eb3-b16a-084d5a1e809e\",\n          \"f415d07a-7f7e-4251-939b-f0b4e41d3f54\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"email\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100000,\n        \"samples\": [\n          \"13668e05_dc59_4508_8175_6cb5a34f6d9c@zakyfoundation.org\",\n          \"02814af4_c418_4eb3_b16a_084d5a1e809e@startupcampus.id\",\n          \"f415d07a_7f7e_4251_939b_f0b4e41d3f54@startupcampus.id\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Men\",\n          \"Women\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"birthdate\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 13003,\n        \"samples\": [\n          \"28/07/1974\",\n          \"24/10/1983\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"device_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Android\",\n          \"iOS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"device_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100000,\n        \"samples\": [\n          \"9498c666-564b-45f2-bc36-41f1205c97c9\",\n          \"edcaac4a-6082-4d8e-a509-a7c3b91dae7d\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"device_version\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 86,\n        \"samples\": [\n          \"Android 9\",\n          \"iPhone; CPU iPhone OS 14_2_1 like Mac OS X\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"home_location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 33,\n        \"samples\": [\n          \"Sulawesi Tengah\",\n          \"Maluku\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"home_country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Indonesia\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"first_join_date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 2223,\n        \"samples\": [\n          \"11/06/2022\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 7,\n        \"max\": 69,\n        \"num_unique_values\": 61,\n        \"samples\": [\n          27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"past_trans\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 48969,\n        \"samples\": [\n          \"['Mother Earth Women Green Printed Kurta', 'Be For Bag Women Combo pack Tote Bags', 'Timex Empera Men Gold Toned Dial Watch NL11', 'Lotto Men White Sports Shoes', 'Wills Lifestyle Women Yellow Shirt', 'Fila Women Blue Flip Flops', 'Doodle Boys Printed Green T-shirt', 'Prafful Grey & Maroon Sari', 'Numero Uno Men Black Canvas Shoe', 'Lotto Women Koro W Black Flip Flops', 'John Miller Men Blue Check Shirt', \\\"Myntra Men's I Am Not Lazy Yellow T-shirt\\\", 'Puma Men Graphic Green T-shirt', 'Park Avenue Men Copper Tie', 'Taylor of London Women White Satin Perfumed body Spray', 'John Miller Men Black Trousers', 'Catwalk Women Silver Flats', 'CASIO ENTICER Men White Dial Chronograph Watch A656', 'Reebok Men Heather Grey T-shirt', 'Wildcraft Unisex Blue Backpack', 'Rocia Women Beige Flats']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "customer_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-9eca8488-cc74-4a61-85c1-c66814dfc3db\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>username</th>\n",
       "      <th>email</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>device_type</th>\n",
       "      <th>device_id</th>\n",
       "      <th>device_version</th>\n",
       "      <th>home_location</th>\n",
       "      <th>home_country</th>\n",
       "      <th>first_join_date</th>\n",
       "      <th>age</th>\n",
       "      <th>past_trans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2870</td>\n",
       "      <td>Lala</td>\n",
       "      <td>Maryati</td>\n",
       "      <td>671a0865-ac4e-4dc4-9c4f-c286a1176f7e</td>\n",
       "      <td>671a0865_ac4e_4dc4_9c4f_c286a1176f7e@startupca...</td>\n",
       "      <td>Women</td>\n",
       "      <td>14/06/1996</td>\n",
       "      <td>iOS</td>\n",
       "      <td>c9c0de76-0a6c-4ac2-843f-65264ab9fe63</td>\n",
       "      <td>iPhone; CPU iPhone OS 14_2_1 like Mac OS X</td>\n",
       "      <td>Sumatera Barat</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>21/07/2019</td>\n",
       "      <td>27</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8193</td>\n",
       "      <td>Maimunah</td>\n",
       "      <td>Laksmiwati</td>\n",
       "      <td>83be2ba7-8133-48a4-bbcb-b46a2762473f</td>\n",
       "      <td>83be2ba7_8133_48a4_bbcb_b46a2762473f@zakyfound...</td>\n",
       "      <td>Women</td>\n",
       "      <td>16/08/1993</td>\n",
       "      <td>Android</td>\n",
       "      <td>fb331c3d-f42e-40fe-afe2-b4b73a8a6e25</td>\n",
       "      <td>Android 2.2.1</td>\n",
       "      <td>Jakarta Raya</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>16/07/2017</td>\n",
       "      <td>30</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7279</td>\n",
       "      <td>Bakiman</td>\n",
       "      <td>Simanjuntak</td>\n",
       "      <td>3250e5a3-1d23-4675-a647-3281879d42be</td>\n",
       "      <td>3250e5a3_1d23_4675_a647_3281879d42be@startupca...</td>\n",
       "      <td>Men</td>\n",
       "      <td>23/01/1989</td>\n",
       "      <td>iOS</td>\n",
       "      <td>d13dde0a-6ae1-43c3-83a7-11bbb922730b</td>\n",
       "      <td>iPad; CPU iPad OS 4_2_1 like Mac OS X</td>\n",
       "      <td>Nusa Tenggara Barat</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>23/08/2020</td>\n",
       "      <td>35</td>\n",
       "      <td>['Lino Perros Women Solid Brown Belt', \"Puma W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88813</td>\n",
       "      <td>Cahyadi</td>\n",
       "      <td>Maheswara</td>\n",
       "      <td>df797edf-b465-4a80-973b-9fbb612260c2</td>\n",
       "      <td>df797edf_b465_4a80_973b_9fbb612260c2@zakyfound...</td>\n",
       "      <td>Men</td>\n",
       "      <td>05/01/1991</td>\n",
       "      <td>iOS</td>\n",
       "      <td>f4c18515-c5be-419f-8142-f037be47c9cd</td>\n",
       "      <td>iPad; CPU iPad OS 14_2 like Mac OS X</td>\n",
       "      <td>Kalimantan Timur</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>03/10/2021</td>\n",
       "      <td>33</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82542</td>\n",
       "      <td>Irnanto</td>\n",
       "      <td>Wijaya</td>\n",
       "      <td>36ab08e1-03de-42a8-9e3b-59528c798824</td>\n",
       "      <td>36ab08e1_03de_42a8_9e3b_59528c798824@startupca...</td>\n",
       "      <td>Men</td>\n",
       "      <td>15/07/2000</td>\n",
       "      <td>iOS</td>\n",
       "      <td>e46e4c36-4630-4736-8fcf-663db29ca3b0</td>\n",
       "      <td>iPhone; CPU iPhone OS 10_3_3 like Mac OS X</td>\n",
       "      <td>Kalimantan Selatan</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>11/04/2021</td>\n",
       "      <td>23</td>\n",
       "      <td>['Arrow Woman Lana White Shirt']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9eca8488-cc74-4a61-85c1-c66814dfc3db')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-9eca8488-cc74-4a61-85c1-c66814dfc3db button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-9eca8488-cc74-4a61-85c1-c66814dfc3db');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-952436f5-6730-4e53-ae19-3e1c55b0eb7f\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-952436f5-6730-4e53-ae19-3e1c55b0eb7f')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-952436f5-6730-4e53-ae19-3e1c55b0eb7f button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   customer_id first_name    last_name                              username  \\\n",
       "0         2870       Lala      Maryati  671a0865-ac4e-4dc4-9c4f-c286a1176f7e   \n",
       "1         8193   Maimunah   Laksmiwati  83be2ba7-8133-48a4-bbcb-b46a2762473f   \n",
       "2         7279    Bakiman  Simanjuntak  3250e5a3-1d23-4675-a647-3281879d42be   \n",
       "3        88813    Cahyadi    Maheswara  df797edf-b465-4a80-973b-9fbb612260c2   \n",
       "4        82542    Irnanto       Wijaya  36ab08e1-03de-42a8-9e3b-59528c798824   \n",
       "\n",
       "                                               email gender   birthdate  \\\n",
       "0  671a0865_ac4e_4dc4_9c4f_c286a1176f7e@startupca...  Women  14/06/1996   \n",
       "1  83be2ba7_8133_48a4_bbcb_b46a2762473f@zakyfound...  Women  16/08/1993   \n",
       "2  3250e5a3_1d23_4675_a647_3281879d42be@startupca...    Men  23/01/1989   \n",
       "3  df797edf_b465_4a80_973b_9fbb612260c2@zakyfound...    Men  05/01/1991   \n",
       "4  36ab08e1_03de_42a8_9e3b_59528c798824@startupca...    Men  15/07/2000   \n",
       "\n",
       "  device_type                             device_id  \\\n",
       "0         iOS  c9c0de76-0a6c-4ac2-843f-65264ab9fe63   \n",
       "1     Android  fb331c3d-f42e-40fe-afe2-b4b73a8a6e25   \n",
       "2         iOS  d13dde0a-6ae1-43c3-83a7-11bbb922730b   \n",
       "3         iOS  f4c18515-c5be-419f-8142-f037be47c9cd   \n",
       "4         iOS  e46e4c36-4630-4736-8fcf-663db29ca3b0   \n",
       "\n",
       "                               device_version        home_location  \\\n",
       "0  iPhone; CPU iPhone OS 14_2_1 like Mac OS X       Sumatera Barat   \n",
       "1                               Android 2.2.1         Jakarta Raya   \n",
       "2       iPad; CPU iPad OS 4_2_1 like Mac OS X  Nusa Tenggara Barat   \n",
       "3        iPad; CPU iPad OS 14_2 like Mac OS X     Kalimantan Timur   \n",
       "4  iPhone; CPU iPhone OS 10_3_3 like Mac OS X   Kalimantan Selatan   \n",
       "\n",
       "  home_country first_join_date  age  \\\n",
       "0    Indonesia      21/07/2019   27   \n",
       "1    Indonesia      16/07/2017   30   \n",
       "2    Indonesia      23/08/2020   35   \n",
       "3    Indonesia      03/10/2021   33   \n",
       "4    Indonesia      11/04/2021   23   \n",
       "\n",
       "                                          past_trans  \n",
       "0                                                 []  \n",
       "1                                                 []  \n",
       "2  ['Lino Perros Women Solid Brown Belt', \"Puma W...  \n",
       "3                                                 []  \n",
       "4                   ['Arrow Woman Lana White Shirt']  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_df = pd.read_csv('processed_customer_final.csv', encoding='utf-8')\n",
    "customer_df = customer_df.iloc[: , 1:]\n",
    "customer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1AjHj9fNrArV",
    "outputId": "30c5576e-9771-4607-82a5-e1df0c9a47f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count   Dtype \n",
      "---  ------           --------------   ----- \n",
      " 0   customer_id      100000 non-null  int64 \n",
      " 1   first_name       100000 non-null  object\n",
      " 2   last_name        100000 non-null  object\n",
      " 3   username         100000 non-null  object\n",
      " 4   email            100000 non-null  object\n",
      " 5   gender           100000 non-null  object\n",
      " 6   birthdate        100000 non-null  object\n",
      " 7   device_type      100000 non-null  object\n",
      " 8   device_id        100000 non-null  object\n",
      " 9   device_version   100000 non-null  object\n",
      " 10  home_location    100000 non-null  object\n",
      " 11  home_country     100000 non-null  object\n",
      " 12  first_join_date  100000 non-null  object\n",
      " 13  age              100000 non-null  int64 \n",
      " 14  past_trans       100000 non-null  object\n",
      "dtypes: int64(2), object(13)\n",
      "memory usage: 11.4+ MB\n"
     ]
    }
   ],
   "source": [
    "customer_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "S0uEgtE4rArW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "FnT8LJ01pdWb",
    "outputId": "d413ee8d-1be1-45f1-e407-a50cd44d835a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-2.68268585e-02  6.60445839e-02  1.56628564e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-3.63447741e-02 -1.79072991e-02  1.01005035e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-8.63776952e-02 -4.10641469e-02  3.33572179e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-4.90391180e-02 -1.59678720e-02 -3.54683548e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-2.36744732e-02  4.10940349e-02 -2.29127221e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> object</label>"
      ],
      "text/plain": [
       "0    [-2.68268585e-02  6.60445839e-02  1.56628564e-...\n",
       "1    [-3.63447741e-02 -1.79072991e-02  1.01005035e-...\n",
       "2    [-8.63776952e-02 -4.10641469e-02  3.33572179e-...\n",
       "3    [-4.90391180e-02 -1.59678720e-02 -3.54683548e-...\n",
       "4    [-2.36744732e-02  4.10940349e-02 -2.29127221e-...\n",
       "Name: embeddings, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_df['embeddings'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "QfQmP5k3zE3E"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "GQ5v8jkHzE6b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10OJPYwGpdfj"
   },
   "source": [
    "# Product Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "45x2sHFnykjB",
    "outputId": "03325545-a0fd-4173-bae7-ae9b0cc8c5c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.10/dist-packages (1.7.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "8ikEut44SS6A",
    "outputId": "c5aa350e-e711-459a-90bd-9aae238cae3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of distances: (44446, 10), Shape of indices: (44446, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "import faiss\n",
    "\n",
    "\n",
    "# Step 1: Convert embeddings from string to numeric array\n",
    "# Precompile regex to replace whitespaces between numeric values with commas\n",
    "comma_insert_pattern = re.compile(r'(?<=\\d)\\s+(?=-?\\d)')\n",
    "\n",
    "def parse_embedding(embedding_str):\n",
    "    # Assuming the embedding string contains numeric values separated by spaces or commas\n",
    "    try:\n",
    "        # Replace spaces between numbers with commas if needed\n",
    "        formatted_str = comma_insert_pattern.sub(',', embedding_str.strip())\n",
    "        # Convert formatted string into a list and then to float32\n",
    "        return np.array(ast.literal_eval(formatted_str), dtype=np.float32)\n",
    "    except Exception as e:\n",
    "        # Handle parsing failure gracefully by providing a default embedding vector\n",
    "        print(f\"Failed to parse: {embedding_str[:50]}... Error: {e}\")\n",
    "        return np.zeros((768,), dtype=np.float32)  # Assuming 768 dimensions for failure\n",
    "\n",
    "# Apply the function to parse embeddings\n",
    "product_df['embeddings'] = product_df['embeddings'].apply(parse_embedding)\n",
    "\n",
    "# Step 2: Stack embeddings into a 2D array with float32 data type\n",
    "try:\n",
    "    product_embeddings = np.stack(product_df['embeddings'].values).astype(np.float32)\n",
    "except ValueError as e:\n",
    "    print(\"Failed to stack embeddings. Ensure all embeddings have the same dimension.\")\n",
    "    raise e\n",
    "\n",
    "# Step 3: Use Faiss for Efficient Similarity Search\n",
    "d = product_embeddings.shape[1]  # Dimensionality of embeddings\n",
    "index = faiss.IndexFlatL2(d)  # Use L2 distance for similarity\n",
    "\n",
    "# Add embeddings to the Faiss index\n",
    "index.add(product_embeddings)\n",
    "\n",
    "# Search for top 10 similar items for each product\n",
    "k = 10\n",
    "distances, indices = index.search(product_embeddings, k)\n",
    "\n",
    "# Print the shape of the results to confirm\n",
    "print(f\"Shape of distances: {distances.shape}, Shape of indices: {indices.shape}\")\n",
    "\n",
    "# Step 4: Create a DataFrame with similarity information for each product\n",
    "similarity_results = []\n",
    "\n",
    "for i, (dist_row, ind_row) in enumerate(zip(distances, indices)):\n",
    "    product_id = product_df.iloc[i]['id']\n",
    "    for dist, ind in zip(dist_row, ind_row):\n",
    "        similar_product_id = product_df.iloc[ind]['id']\n",
    "        similarity_results.append({\n",
    "            'product_id': product_id,\n",
    "            'similar_product_id': similar_product_id,\n",
    "            'distance': dist\n",
    "        })\n",
    "\n",
    "similarity_df = pd.DataFrame(similarity_results)\n",
    "\n",
    "# Print a sample of the similarity DataFrame\n",
    "#print(similarity_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "bgMammvDLRm1"
   },
   "outputs": [],
   "source": [
    "# Save the similarity DataFrame to a CSV file\n",
    "similarity_df.to_csv('product_similarity_matrix.csv', index=False)\n",
    "\n",
    "import pickle\n",
    "# Alternatively, save as a pickle for faster loading\n",
    "similarity_df.to_pickle('product_similarity_matrix.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "Fz5SdtQdMq_S"
   },
   "outputs": [],
   "source": [
    "# Load the similarity DataFrame from the CSV file\n",
    "similarity_df = pd.read_csv('product_similarity_matrix.csv')\n",
    "\n",
    "# Or load from the pickle file\n",
    "similarity_df = pd.read_pickle('product_similarity_matrix.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dWBxkvPDLVGQ",
    "outputId": "ab2aa8c6-45a6-4cec-cadd-5c1f1cca7260"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 similar products to product ID 15970:\n",
      "   product_id  similar_product_id  distance\n",
      "0       15970               15970  0.000000\n",
      "1       15970               26396  0.049105\n",
      "2       15970               15996  0.069805\n",
      "3       15970               15994  0.069805\n",
      "4       15970               15992  0.069805\n",
      "5       15970               15972  0.090451\n",
      "6       15970               15993  0.112898\n",
      "7       15970               15974  0.127551\n",
      "8       15970               15981  0.133185\n",
      "9       15970               15968  0.133185\n"
     ]
    }
   ],
   "source": [
    "# Run an Experiment for Product ID\n",
    "product_id = 15970\n",
    "\n",
    "# Check if the product ID exists in the DataFrame\n",
    "if product_id in similarity_df['product_id'].values:\n",
    "    # Filter out the rows with the given product_id\n",
    "    similar_products = similarity_df[similarity_df['product_id'] == product_id]\n",
    "\n",
    "    # Sort by distance to get the most similar products first (lower distance is more similar)\n",
    "    similar_products = similar_products.sort_values(by='distance')\n",
    "\n",
    "    # Print the top 10 similar products\n",
    "    print(f\"Top 10 similar products to product ID {product_id}:\")\n",
    "    print(similar_products.head(10))\n",
    "else:\n",
    "    print(f\"Product ID {product_id} not found in the similarity data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "4Uc2TbSeykln"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "C9SVIbSsykog"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "n61eN-8Epk_N"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mtBoCtPtkRc"
   },
   "source": [
    "# User Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "id": "xCXEuDRvplBk"
   },
   "outputs": [],
   "source": [
    "# Step 1: Convert `past_trans` strings to lists\n",
    "def parse_past_transactions(past_trans_str):\n",
    "    if isinstance(past_trans_str, str) and past_trans_str.strip():\n",
    "        try:\n",
    "            # Clean up potential issues in the string by removing unwanted characters\n",
    "            # Retain only alphanumeric characters and certain symbols\n",
    "            cleaned_str = re.sub(r'[^a-zA-Z0-9\\s,\\[\\]\\(\\)\\{\\}\\-\\'\"]', '', past_trans_str)\n",
    "\n",
    "            # Replace single quotes with double quotes for JSON compatibility\n",
    "            cleaned_str = cleaned_str.replace(\"'\", '\"')\n",
    "\n",
    "            # Remove multiple spaces to prevent parsing issues\n",
    "            cleaned_str = re.sub(r'\\s+', ' ', cleaned_str)\n",
    "\n",
    "            # Ensure the cleaned string is formatted properly as a list\n",
    "            if not (cleaned_str.startswith('[') and cleaned_str.endswith(']')):\n",
    "                cleaned_str = f\"[{cleaned_str}]\"\n",
    "\n",
    "            # Try using JSON parsing first (safer)\n",
    "            try:\n",
    "                return json.loads(cleaned_str)\n",
    "            except json.JSONDecodeError:\n",
    "                # Fallback to ast.literal_eval if JSON parsing fails\n",
    "                return ast.literal_eval(cleaned_str)\n",
    "\n",
    "        except (ValueError, SyntaxError) as e:\n",
    "            print(f\"Failed to parse: {past_trans_str[:50]}... Error: {e}\")\n",
    "            return []\n",
    "    elif isinstance(past_trans_str, list):\n",
    "        # If it's already a list, just return it\n",
    "        return past_trans_str\n",
    "    else:\n",
    "        # For NaN or other types, return an empty list\n",
    "        return []\n",
    "\n",
    "# Assume `customer_df` is your DataFrame\n",
    "# Apply the function to parse `past_trans`\n",
    "customer_df['past_trans'] = customer_df['past_trans'].apply(parse_past_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 711
    },
    "id": "3czzgD7CFK8i",
    "outputId": "3deb597b-2bea-45bd-ab24-016ed739219d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>past_trans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Arrow Woman Lana White Shirt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Spykar Men Check Red Shirts, Puma Men Trainin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Wildcraft Lavender Grey Slingbag, Folklore Wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[Puma Women Flash Black Watch, Colorbar Extra ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[United Colors of Benetton Women Green T-shirt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[Provogue Men Brown Formal Shoes, Titan Men Br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[Ganuchi Men Navy Suede Casual Shoes, Lencia S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[Nike Women Casual Blue Capri, Mark Taylor Men...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> object</label>"
      ],
      "text/plain": [
       "0                                                    []\n",
       "1                                                    []\n",
       "2                                                    []\n",
       "3                                                    []\n",
       "4                        [Arrow Woman Lana White Shirt]\n",
       "5                                                    []\n",
       "6                                                    []\n",
       "7     [Spykar Men Check Red Shirts, Puma Men Trainin...\n",
       "8     [Wildcraft Lavender Grey Slingbag, Folklore Wo...\n",
       "9                                                    []\n",
       "10                                                   []\n",
       "11                                                   []\n",
       "12    [Puma Women Flash Black Watch, Colorbar Extra ...\n",
       "13                                                   []\n",
       "14                                                   []\n",
       "15    [United Colors of Benetton Women Green T-shirt...\n",
       "16    [Provogue Men Brown Formal Shoes, Titan Men Br...\n",
       "17                                                   []\n",
       "18    [Ganuchi Men Navy Suede Casual Shoes, Lencia S...\n",
       "19    [Nike Women Casual Blue Capri, Mark Taylor Men...\n",
       "Name: past_trans, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_df['past_trans'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8dbUj-U_Jtd5",
    "outputId": "7b437bf3-5ee1-4ed3-b62b-70a7c165c730"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All rows were successfully parsed as lists.\n"
     ]
    }
   ],
   "source": [
    "# Check how many rows are not successfully parsed\n",
    "not_parsed_count = (~are_all_parsed).sum()\n",
    "\n",
    "# If any rows are not successfully parsed, print the corresponding rows\n",
    "if not_parsed_count > 0:\n",
    "    print(f\"Number of rows not successfully parsed: {not_parsed_count}\")\n",
    "    print(\"Rows that failed to parse:\")\n",
    "    print(customer_df[~are_all_parsed])\n",
    "else:\n",
    "    print(\"All rows were successfully parsed as lists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "tlOe_Up3ORYQ",
    "outputId": "474f08be-2b63-4579-dc62-08ec5c09911e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-34fc7a11cb38>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "S-rnbaB1plD6"
   },
   "outputs": [],
   "source": [
    "# Step 2: Create User-Item Interaction Matrix (Sparse Representation)\n",
    "from scipy.sparse import csr_matrix\n",
    "# Get all unique product IDs from past transactions\n",
    "all_products = set()\n",
    "customer_df['past_trans'].apply(lambda x: all_products.update(x))\n",
    "\n",
    "# Create a mapping from product ID to column index\n",
    "product_to_index = {product: idx for idx, product in enumerate(all_products)}\n",
    "\n",
    "# Initialize lists to construct a sparse matrix\n",
    "row_indices = []\n",
    "col_indices = []\n",
    "data = []\n",
    "\n",
    "# Populate the data for the sparse user-item matrix\n",
    "for user_idx, past_trans in enumerate(customer_df['past_trans']):\n",
    "    for product in past_trans:\n",
    "        if product in product_to_index:\n",
    "            product_idx = product_to_index[product]\n",
    "            row_indices.append(user_idx)\n",
    "            col_indices.append(product_idx)\n",
    "            data.append(1)\n",
    "\n",
    "# Create a sparse user-item interaction matrix\n",
    "n_users = customer_df.shape[0]\n",
    "n_products = len(all_products)\n",
    "user_item_sparse_matrix = csr_matrix((data, (row_indices, col_indices)), shape=(n_users, n_products))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xfWnpgkYgQBh",
    "outputId": "f56113a4-4427-4c5d-9fb9-1db4418605f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of User-Item Interaction Matrix: (100000, 26736)\n",
      "Number of non-zero entries (interactions): 124874\n",
      "\n",
      "Sample of User-Item Interaction Matrix (first 5 users and 10 products):\n",
      "        Product_0  Product_1  Product_2  Product_3  Product_4  Product_5  \\\n",
      "User_0          0          0          0          0          0          0   \n",
      "User_1          0          0          0          0          0          0   \n",
      "User_2          0          0          0          0          0          0   \n",
      "User_3          0          0          0          0          0          0   \n",
      "User_4          0          0          0          0          0          0   \n",
      "\n",
      "        Product_6  Product_7  Product_8  Product_9  \n",
      "User_0          0          0          0          0  \n",
      "User_1          0          0          0          0  \n",
      "User_2          0          0          0          0  \n",
      "User_3          0          0          0          0  \n",
      "User_4          0          0          0          0  \n"
     ]
    }
   ],
   "source": [
    "# Print some details about the matrix\n",
    "print(\"Shape of User-Item Interaction Matrix:\", user_item_sparse_matrix.shape)\n",
    "print(\"Number of non-zero entries (interactions):\", user_item_sparse_matrix.nnz)\n",
    "\n",
    "# Convert a small portion of the matrix to dense format for display\n",
    "# Display interactions for the first 5 users and first 10 products\n",
    "sample_matrix = user_item_sparse_matrix[:5, :10].toarray()\n",
    "\n",
    "# Convert to DataFrame for better readability\n",
    "sample_df = pd.DataFrame(sample_matrix, columns=[f\"Product_{i}\" for i in range(10)])\n",
    "sample_df.index = [f\"User_{i}\" for i in range(5)]\n",
    "\n",
    "print(\"\\nSample of User-Item Interaction Matrix (first 5 users and 10 products):\")\n",
    "print(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jC8blHjeF0OO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vrRls3Rwg1cy"
   },
   "source": [
    "User-User Similarity Matrix: This matrix represents the similarity between users based on their item interactions. It is key for user-based collaborative filtering, where recommendations are made by finding users with similar interaction patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "071LQWovplGg",
    "outputId": "fbbb2cd6-928e-4ff8-adeb-a4ec6176214b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch from user 0 to user 100\n",
      "Processing batch from user 100 to user 200\n",
      "Processing batch from user 200 to user 300\n",
      "Processing batch from user 300 to user 400\n",
      "Processing batch from user 400 to user 500\n",
      "Processing batch from user 500 to user 600\n",
      "Processing batch from user 600 to user 700\n",
      "Processing batch from user 700 to user 800\n",
      "Processing batch from user 800 to user 900\n",
      "Processing batch from user 900 to user 1000\n",
      "Processing batch from user 1000 to user 1100\n",
      "Processing batch from user 1100 to user 1200\n",
      "Processing batch from user 1200 to user 1300\n",
      "Processing batch from user 1300 to user 1400\n",
      "Processing batch from user 1400 to user 1500\n",
      "Processing batch from user 1500 to user 1600\n",
      "Processing batch from user 1600 to user 1700\n",
      "Processing batch from user 1700 to user 1800\n",
      "Processing batch from user 1800 to user 1900\n",
      "Processing batch from user 1900 to user 2000\n",
      "Processing batch from user 2000 to user 2100\n",
      "Processing batch from user 2100 to user 2200\n",
      "Processing batch from user 2200 to user 2300\n",
      "Processing batch from user 2300 to user 2400\n",
      "Processing batch from user 2400 to user 2500\n",
      "Processing batch from user 2500 to user 2600\n",
      "Processing batch from user 2600 to user 2700\n",
      "Processing batch from user 2700 to user 2800\n",
      "Processing batch from user 2800 to user 2900\n",
      "Processing batch from user 2900 to user 3000\n",
      "Processing batch from user 3000 to user 3100\n",
      "Processing batch from user 3100 to user 3200\n",
      "Processing batch from user 3200 to user 3300\n",
      "Processing batch from user 3300 to user 3400\n",
      "Processing batch from user 3400 to user 3500\n",
      "Processing batch from user 3500 to user 3600\n",
      "Processing batch from user 3600 to user 3700\n",
      "Processing batch from user 3700 to user 3800\n",
      "Processing batch from user 3800 to user 3900\n",
      "Processing batch from user 3900 to user 4000\n",
      "Processing batch from user 4000 to user 4100\n",
      "Processing batch from user 4100 to user 4200\n",
      "Processing batch from user 4200 to user 4300\n",
      "Processing batch from user 4300 to user 4400\n",
      "Processing batch from user 4400 to user 4500\n",
      "Processing batch from user 4500 to user 4600\n",
      "Processing batch from user 4600 to user 4700\n",
      "Processing batch from user 4700 to user 4800\n",
      "Processing batch from user 4800 to user 4900\n",
      "Processing batch from user 4900 to user 5000\n",
      "Processing batch from user 5000 to user 5100\n",
      "Processing batch from user 5100 to user 5200\n",
      "Processing batch from user 5200 to user 5300\n",
      "Processing batch from user 5300 to user 5400\n",
      "Processing batch from user 5400 to user 5500\n",
      "Processing batch from user 5500 to user 5600\n",
      "Processing batch from user 5600 to user 5700\n",
      "Processing batch from user 5700 to user 5800\n",
      "Processing batch from user 5800 to user 5900\n",
      "Processing batch from user 5900 to user 6000\n",
      "Processing batch from user 6000 to user 6100\n",
      "Processing batch from user 6100 to user 6200\n",
      "Processing batch from user 6200 to user 6300\n",
      "Processing batch from user 6300 to user 6400\n",
      "Processing batch from user 6400 to user 6500\n",
      "Processing batch from user 6500 to user 6600\n",
      "Processing batch from user 6600 to user 6700\n",
      "Processing batch from user 6700 to user 6800\n",
      "Processing batch from user 6800 to user 6900\n",
      "Processing batch from user 6900 to user 7000\n",
      "Processing batch from user 7000 to user 7100\n",
      "Processing batch from user 7100 to user 7200\n",
      "Processing batch from user 7200 to user 7300\n",
      "Processing batch from user 7300 to user 7400\n",
      "Processing batch from user 7400 to user 7500\n",
      "Processing batch from user 7500 to user 7600\n",
      "Processing batch from user 7600 to user 7700\n",
      "Processing batch from user 7700 to user 7800\n",
      "Processing batch from user 7800 to user 7900\n",
      "Processing batch from user 7900 to user 8000\n",
      "Processing batch from user 8000 to user 8100\n",
      "Processing batch from user 8100 to user 8200\n",
      "Processing batch from user 8200 to user 8300\n",
      "Processing batch from user 8300 to user 8400\n",
      "Processing batch from user 8400 to user 8500\n",
      "Processing batch from user 8500 to user 8600\n",
      "Processing batch from user 8600 to user 8700\n",
      "Processing batch from user 8700 to user 8800\n",
      "Processing batch from user 8800 to user 8900\n",
      "Processing batch from user 8900 to user 9000\n",
      "Processing batch from user 9000 to user 9100\n",
      "Processing batch from user 9100 to user 9200\n",
      "Processing batch from user 9200 to user 9300\n",
      "Processing batch from user 9300 to user 9400\n",
      "Processing batch from user 9400 to user 9500\n",
      "Processing batch from user 9500 to user 9600\n",
      "Processing batch from user 9600 to user 9700\n",
      "Processing batch from user 9700 to user 9800\n",
      "Processing batch from user 9800 to user 9900\n",
      "Processing batch from user 9900 to user 10000\n",
      "Processing batch from user 10000 to user 10100\n",
      "Processing batch from user 10100 to user 10200\n",
      "Processing batch from user 10200 to user 10300\n",
      "Processing batch from user 10300 to user 10400\n",
      "Processing batch from user 10400 to user 10500\n",
      "Processing batch from user 10500 to user 10600\n",
      "Processing batch from user 10600 to user 10700\n",
      "Processing batch from user 10700 to user 10800\n",
      "Processing batch from user 10800 to user 10900\n",
      "Processing batch from user 10900 to user 11000\n",
      "Processing batch from user 11000 to user 11100\n",
      "Processing batch from user 11100 to user 11200\n",
      "Processing batch from user 11200 to user 11300\n",
      "Processing batch from user 11300 to user 11400\n",
      "Processing batch from user 11400 to user 11500\n",
      "Processing batch from user 11500 to user 11600\n",
      "Processing batch from user 11600 to user 11700\n",
      "Processing batch from user 11700 to user 11800\n",
      "Processing batch from user 11800 to user 11900\n",
      "Processing batch from user 11900 to user 12000\n",
      "Processing batch from user 12000 to user 12100\n",
      "Processing batch from user 12100 to user 12200\n",
      "Processing batch from user 12200 to user 12300\n",
      "Processing batch from user 12300 to user 12400\n",
      "Processing batch from user 12400 to user 12500\n",
      "Processing batch from user 12500 to user 12600\n",
      "Processing batch from user 12600 to user 12700\n",
      "Processing batch from user 12700 to user 12800\n",
      "Processing batch from user 12800 to user 12900\n",
      "Processing batch from user 12900 to user 13000\n",
      "Processing batch from user 13000 to user 13100\n",
      "Processing batch from user 13100 to user 13200\n",
      "Processing batch from user 13200 to user 13300\n",
      "Processing batch from user 13300 to user 13400\n",
      "Processing batch from user 13400 to user 13500\n",
      "Processing batch from user 13500 to user 13600\n",
      "Processing batch from user 13600 to user 13700\n",
      "Processing batch from user 13700 to user 13800\n",
      "Processing batch from user 13800 to user 13900\n",
      "Processing batch from user 13900 to user 14000\n",
      "Processing batch from user 14000 to user 14100\n",
      "Processing batch from user 14100 to user 14200\n",
      "Processing batch from user 14200 to user 14300\n",
      "Processing batch from user 14300 to user 14400\n",
      "Processing batch from user 14400 to user 14500\n",
      "Processing batch from user 14500 to user 14600\n",
      "Processing batch from user 14600 to user 14700\n",
      "Processing batch from user 14700 to user 14800\n",
      "Processing batch from user 14800 to user 14900\n",
      "Processing batch from user 14900 to user 15000\n",
      "Processing batch from user 15000 to user 15100\n",
      "Processing batch from user 15100 to user 15200\n",
      "Processing batch from user 15200 to user 15300\n",
      "Processing batch from user 15300 to user 15400\n",
      "Processing batch from user 15400 to user 15500\n",
      "Processing batch from user 15500 to user 15600\n",
      "Processing batch from user 15600 to user 15700\n",
      "Processing batch from user 15700 to user 15800\n",
      "Processing batch from user 15800 to user 15900\n",
      "Processing batch from user 15900 to user 16000\n",
      "Processing batch from user 16000 to user 16100\n",
      "Processing batch from user 16100 to user 16200\n",
      "Processing batch from user 16200 to user 16300\n",
      "Processing batch from user 16300 to user 16400\n",
      "Processing batch from user 16400 to user 16500\n",
      "Processing batch from user 16500 to user 16600\n",
      "Processing batch from user 16600 to user 16700\n",
      "Processing batch from user 16700 to user 16800\n",
      "Processing batch from user 16800 to user 16900\n",
      "Processing batch from user 16900 to user 17000\n",
      "Processing batch from user 17000 to user 17100\n",
      "Processing batch from user 17100 to user 17200\n",
      "Processing batch from user 17200 to user 17300\n",
      "Processing batch from user 17300 to user 17400\n",
      "Processing batch from user 17400 to user 17500\n",
      "Processing batch from user 17500 to user 17600\n",
      "Processing batch from user 17600 to user 17700\n",
      "Processing batch from user 17700 to user 17800\n",
      "Processing batch from user 17800 to user 17900\n",
      "Processing batch from user 17900 to user 18000\n",
      "Processing batch from user 18000 to user 18100\n",
      "Processing batch from user 18100 to user 18200\n",
      "Processing batch from user 18200 to user 18300\n",
      "Processing batch from user 18300 to user 18400\n",
      "Processing batch from user 18400 to user 18500\n",
      "Processing batch from user 18500 to user 18600\n",
      "Processing batch from user 18600 to user 18700\n",
      "Processing batch from user 18700 to user 18800\n",
      "Processing batch from user 18800 to user 18900\n",
      "Processing batch from user 18900 to user 19000\n",
      "Processing batch from user 19000 to user 19100\n",
      "Processing batch from user 19100 to user 19200\n",
      "Processing batch from user 19200 to user 19300\n",
      "Processing batch from user 19300 to user 19400\n",
      "Processing batch from user 19400 to user 19500\n",
      "Processing batch from user 19500 to user 19600\n",
      "Processing batch from user 19600 to user 19700\n",
      "Processing batch from user 19700 to user 19800\n",
      "Processing batch from user 19800 to user 19900\n",
      "Processing batch from user 19900 to user 20000\n",
      "Processing batch from user 20000 to user 20100\n",
      "Processing batch from user 20100 to user 20200\n",
      "Processing batch from user 20200 to user 20300\n",
      "Processing batch from user 20300 to user 20400\n",
      "Processing batch from user 20400 to user 20500\n",
      "Processing batch from user 20500 to user 20600\n",
      "Processing batch from user 20600 to user 20700\n",
      "Processing batch from user 20700 to user 20800\n",
      "Processing batch from user 20800 to user 20900\n",
      "Processing batch from user 20900 to user 21000\n",
      "Processing batch from user 21000 to user 21100\n",
      "Processing batch from user 21100 to user 21200\n",
      "Processing batch from user 21200 to user 21300\n",
      "Processing batch from user 21300 to user 21400\n",
      "Processing batch from user 21400 to user 21500\n",
      "Processing batch from user 21500 to user 21600\n",
      "Processing batch from user 21600 to user 21700\n",
      "Processing batch from user 21700 to user 21800\n",
      "Processing batch from user 21800 to user 21900\n",
      "Processing batch from user 21900 to user 22000\n",
      "Processing batch from user 22000 to user 22100\n",
      "Processing batch from user 22100 to user 22200\n",
      "Processing batch from user 22200 to user 22300\n",
      "Processing batch from user 22300 to user 22400\n",
      "Processing batch from user 22400 to user 22500\n",
      "Processing batch from user 22500 to user 22600\n",
      "Processing batch from user 22600 to user 22700\n",
      "Processing batch from user 22700 to user 22800\n",
      "Processing batch from user 22800 to user 22900\n",
      "Processing batch from user 22900 to user 23000\n",
      "Processing batch from user 23000 to user 23100\n",
      "Processing batch from user 23100 to user 23200\n",
      "Processing batch from user 23200 to user 23300\n",
      "Processing batch from user 23300 to user 23400\n",
      "Processing batch from user 23400 to user 23500\n",
      "Processing batch from user 23500 to user 23600\n",
      "Processing batch from user 23600 to user 23700\n",
      "Processing batch from user 23700 to user 23800\n",
      "Processing batch from user 23800 to user 23900\n",
      "Processing batch from user 23900 to user 24000\n",
      "Processing batch from user 24000 to user 24100\n",
      "Processing batch from user 24100 to user 24200\n",
      "Processing batch from user 24200 to user 24300\n",
      "Processing batch from user 24300 to user 24400\n",
      "Processing batch from user 24400 to user 24500\n",
      "Processing batch from user 24500 to user 24600\n",
      "Processing batch from user 24600 to user 24700\n",
      "Processing batch from user 24700 to user 24800\n",
      "Processing batch from user 24800 to user 24900\n",
      "Processing batch from user 24900 to user 25000\n",
      "Processing batch from user 25000 to user 25100\n",
      "Processing batch from user 25100 to user 25200\n",
      "Processing batch from user 25200 to user 25300\n",
      "Processing batch from user 25300 to user 25400\n",
      "Processing batch from user 25400 to user 25500\n",
      "Processing batch from user 25500 to user 25600\n",
      "Processing batch from user 25600 to user 25700\n",
      "Processing batch from user 25700 to user 25800\n",
      "Processing batch from user 25800 to user 25900\n",
      "Processing batch from user 25900 to user 26000\n",
      "Processing batch from user 26000 to user 26100\n",
      "Processing batch from user 26100 to user 26200\n",
      "Processing batch from user 26200 to user 26300\n",
      "Processing batch from user 26300 to user 26400\n",
      "Processing batch from user 26400 to user 26500\n",
      "Processing batch from user 26500 to user 26600\n",
      "Processing batch from user 26600 to user 26700\n",
      "Processing batch from user 26700 to user 26800\n",
      "Processing batch from user 26800 to user 26900\n",
      "Processing batch from user 26900 to user 27000\n",
      "Processing batch from user 27000 to user 27100\n",
      "Processing batch from user 27100 to user 27200\n",
      "Processing batch from user 27200 to user 27300\n",
      "Processing batch from user 27300 to user 27400\n",
      "Processing batch from user 27400 to user 27500\n",
      "Processing batch from user 27500 to user 27600\n",
      "Processing batch from user 27600 to user 27700\n",
      "Processing batch from user 27700 to user 27800\n",
      "Processing batch from user 27800 to user 27900\n",
      "Processing batch from user 27900 to user 28000\n",
      "Processing batch from user 28000 to user 28100\n",
      "Processing batch from user 28100 to user 28200\n",
      "Processing batch from user 28200 to user 28300\n",
      "Processing batch from user 28300 to user 28400\n",
      "Processing batch from user 28400 to user 28500\n",
      "Processing batch from user 28500 to user 28600\n",
      "Processing batch from user 28600 to user 28700\n",
      "Processing batch from user 28700 to user 28800\n",
      "Processing batch from user 28800 to user 28900\n",
      "Processing batch from user 28900 to user 29000\n",
      "Processing batch from user 29000 to user 29100\n",
      "Processing batch from user 29100 to user 29200\n",
      "Processing batch from user 29200 to user 29300\n",
      "Processing batch from user 29300 to user 29400\n",
      "Processing batch from user 29400 to user 29500\n",
      "Processing batch from user 29500 to user 29600\n",
      "Processing batch from user 29600 to user 29700\n",
      "Processing batch from user 29700 to user 29800\n",
      "Processing batch from user 29800 to user 29900\n",
      "Processing batch from user 29900 to user 30000\n",
      "Processing batch from user 30000 to user 30100\n",
      "Processing batch from user 30100 to user 30200\n",
      "Processing batch from user 30200 to user 30300\n",
      "Processing batch from user 30300 to user 30400\n",
      "Processing batch from user 30400 to user 30500\n",
      "Processing batch from user 30500 to user 30600\n",
      "Processing batch from user 30600 to user 30700\n",
      "Processing batch from user 30700 to user 30800\n",
      "Processing batch from user 30800 to user 30900\n",
      "Processing batch from user 30900 to user 31000\n",
      "Processing batch from user 31000 to user 31100\n",
      "Processing batch from user 31100 to user 31200\n",
      "Processing batch from user 31200 to user 31300\n",
      "Processing batch from user 31300 to user 31400\n",
      "Processing batch from user 31400 to user 31500\n",
      "Processing batch from user 31500 to user 31600\n",
      "Processing batch from user 31600 to user 31700\n",
      "Processing batch from user 31700 to user 31800\n",
      "Processing batch from user 31800 to user 31900\n",
      "Processing batch from user 31900 to user 32000\n",
      "Processing batch from user 32000 to user 32100\n",
      "Processing batch from user 32100 to user 32200\n",
      "Processing batch from user 32200 to user 32300\n",
      "Processing batch from user 32300 to user 32400\n",
      "Processing batch from user 32400 to user 32500\n",
      "Processing batch from user 32500 to user 32600\n",
      "Processing batch from user 32600 to user 32700\n",
      "Processing batch from user 32700 to user 32800\n",
      "Processing batch from user 32800 to user 32900\n",
      "Processing batch from user 32900 to user 33000\n",
      "Processing batch from user 33000 to user 33100\n",
      "Processing batch from user 33100 to user 33200\n",
      "Processing batch from user 33200 to user 33300\n",
      "Processing batch from user 33300 to user 33400\n",
      "Processing batch from user 33400 to user 33500\n",
      "Processing batch from user 33500 to user 33600\n",
      "Processing batch from user 33600 to user 33700\n",
      "Processing batch from user 33700 to user 33800\n",
      "Processing batch from user 33800 to user 33900\n",
      "Processing batch from user 33900 to user 34000\n",
      "Processing batch from user 34000 to user 34100\n",
      "Processing batch from user 34100 to user 34200\n",
      "Processing batch from user 34200 to user 34300\n",
      "Processing batch from user 34300 to user 34400\n",
      "Processing batch from user 34400 to user 34500\n",
      "Processing batch from user 34500 to user 34600\n",
      "Processing batch from user 34600 to user 34700\n",
      "Processing batch from user 34700 to user 34800\n",
      "Processing batch from user 34800 to user 34900\n",
      "Processing batch from user 34900 to user 35000\n",
      "Processing batch from user 35000 to user 35100\n",
      "Processing batch from user 35100 to user 35200\n",
      "Processing batch from user 35200 to user 35300\n",
      "Processing batch from user 35300 to user 35400\n",
      "Processing batch from user 35400 to user 35500\n",
      "Processing batch from user 35500 to user 35600\n",
      "Processing batch from user 35600 to user 35700\n",
      "Processing batch from user 35700 to user 35800\n",
      "Processing batch from user 35800 to user 35900\n",
      "Processing batch from user 35900 to user 36000\n",
      "Processing batch from user 36000 to user 36100\n",
      "Processing batch from user 36100 to user 36200\n",
      "Processing batch from user 36200 to user 36300\n",
      "Processing batch from user 36300 to user 36400\n",
      "Processing batch from user 36400 to user 36500\n",
      "Processing batch from user 36500 to user 36600\n",
      "Processing batch from user 36600 to user 36700\n",
      "Processing batch from user 36700 to user 36800\n",
      "Processing batch from user 36800 to user 36900\n",
      "Processing batch from user 36900 to user 37000\n",
      "Processing batch from user 37000 to user 37100\n",
      "Processing batch from user 37100 to user 37200\n",
      "Processing batch from user 37200 to user 37300\n",
      "Processing batch from user 37300 to user 37400\n",
      "Processing batch from user 37400 to user 37500\n",
      "Processing batch from user 37500 to user 37600\n",
      "Processing batch from user 37600 to user 37700\n",
      "Processing batch from user 37700 to user 37800\n",
      "Processing batch from user 37800 to user 37900\n",
      "Processing batch from user 37900 to user 38000\n",
      "Processing batch from user 38000 to user 38100\n",
      "Processing batch from user 38100 to user 38200\n",
      "Processing batch from user 38200 to user 38300\n",
      "Processing batch from user 38300 to user 38400\n",
      "Processing batch from user 38400 to user 38500\n",
      "Processing batch from user 38500 to user 38600\n",
      "Processing batch from user 38600 to user 38700\n",
      "Processing batch from user 38700 to user 38800\n",
      "Processing batch from user 38800 to user 38900\n",
      "Processing batch from user 38900 to user 39000\n",
      "Processing batch from user 39000 to user 39100\n",
      "Processing batch from user 39100 to user 39200\n",
      "Processing batch from user 39200 to user 39300\n",
      "Processing batch from user 39300 to user 39400\n",
      "Processing batch from user 39400 to user 39500\n",
      "Processing batch from user 39500 to user 39600\n",
      "Processing batch from user 39600 to user 39700\n",
      "Processing batch from user 39700 to user 39800\n",
      "Processing batch from user 39800 to user 39900\n",
      "Processing batch from user 39900 to user 40000\n",
      "Processing batch from user 40000 to user 40100\n",
      "Processing batch from user 40100 to user 40200\n",
      "Processing batch from user 40200 to user 40300\n",
      "Processing batch from user 40300 to user 40400\n",
      "Processing batch from user 40400 to user 40500\n",
      "Processing batch from user 40500 to user 40600\n",
      "Processing batch from user 40600 to user 40700\n",
      "Processing batch from user 40700 to user 40800\n",
      "Processing batch from user 40800 to user 40900\n",
      "Processing batch from user 40900 to user 41000\n",
      "Processing batch from user 41000 to user 41100\n",
      "Processing batch from user 41100 to user 41200\n",
      "Processing batch from user 41200 to user 41300\n",
      "Processing batch from user 41300 to user 41400\n",
      "Processing batch from user 41400 to user 41500\n",
      "Processing batch from user 41500 to user 41600\n",
      "Processing batch from user 41600 to user 41700\n",
      "Processing batch from user 41700 to user 41800\n",
      "Processing batch from user 41800 to user 41900\n",
      "Processing batch from user 41900 to user 42000\n",
      "Processing batch from user 42000 to user 42100\n",
      "Processing batch from user 42100 to user 42200\n",
      "Processing batch from user 42200 to user 42300\n",
      "Processing batch from user 42300 to user 42400\n",
      "Processing batch from user 42400 to user 42500\n",
      "Processing batch from user 42500 to user 42600\n",
      "Processing batch from user 42600 to user 42700\n",
      "Processing batch from user 42700 to user 42800\n",
      "Processing batch from user 42800 to user 42900\n",
      "Processing batch from user 42900 to user 43000\n",
      "Processing batch from user 43000 to user 43100\n",
      "Processing batch from user 43100 to user 43200\n",
      "Processing batch from user 43200 to user 43300\n",
      "Processing batch from user 43300 to user 43400\n",
      "Processing batch from user 43400 to user 43500\n",
      "Processing batch from user 43500 to user 43600\n",
      "Processing batch from user 43600 to user 43700\n",
      "Processing batch from user 43700 to user 43800\n",
      "Processing batch from user 43800 to user 43900\n",
      "Processing batch from user 43900 to user 44000\n",
      "Processing batch from user 44000 to user 44100\n",
      "Processing batch from user 44100 to user 44200\n",
      "Processing batch from user 44200 to user 44300\n",
      "Processing batch from user 44300 to user 44400\n",
      "Processing batch from user 44400 to user 44500\n",
      "Processing batch from user 44500 to user 44600\n",
      "Processing batch from user 44600 to user 44700\n",
      "Processing batch from user 44700 to user 44800\n",
      "Processing batch from user 44800 to user 44900\n",
      "Processing batch from user 44900 to user 45000\n",
      "Processing batch from user 45000 to user 45100\n",
      "Processing batch from user 45100 to user 45200\n",
      "Processing batch from user 45200 to user 45300\n",
      "Processing batch from user 45300 to user 45400\n",
      "Processing batch from user 45400 to user 45500\n",
      "Processing batch from user 45500 to user 45600\n",
      "Processing batch from user 45600 to user 45700\n",
      "Processing batch from user 45700 to user 45800\n",
      "Processing batch from user 45800 to user 45900\n",
      "Processing batch from user 45900 to user 46000\n",
      "Processing batch from user 46000 to user 46100\n",
      "Processing batch from user 46100 to user 46200\n",
      "Processing batch from user 46200 to user 46300\n",
      "Processing batch from user 46300 to user 46400\n",
      "Processing batch from user 46400 to user 46500\n",
      "Processing batch from user 46500 to user 46600\n",
      "Processing batch from user 46600 to user 46700\n",
      "Processing batch from user 46700 to user 46800\n",
      "Processing batch from user 46800 to user 46900\n",
      "Processing batch from user 46900 to user 47000\n",
      "Processing batch from user 47000 to user 47100\n",
      "Processing batch from user 47100 to user 47200\n",
      "Processing batch from user 47200 to user 47300\n",
      "Processing batch from user 47300 to user 47400\n",
      "Processing batch from user 47400 to user 47500\n",
      "Processing batch from user 47500 to user 47600\n",
      "Processing batch from user 47600 to user 47700\n",
      "Processing batch from user 47700 to user 47800\n",
      "Processing batch from user 47800 to user 47900\n",
      "Processing batch from user 47900 to user 48000\n",
      "Processing batch from user 48000 to user 48100\n",
      "Processing batch from user 48100 to user 48200\n",
      "Processing batch from user 48200 to user 48300\n",
      "Processing batch from user 48300 to user 48400\n",
      "Processing batch from user 48400 to user 48500\n",
      "Processing batch from user 48500 to user 48600\n",
      "Processing batch from user 48600 to user 48700\n",
      "Processing batch from user 48700 to user 48800\n",
      "Processing batch from user 48800 to user 48900\n",
      "Processing batch from user 48900 to user 49000\n",
      "Processing batch from user 49000 to user 49100\n",
      "Processing batch from user 49100 to user 49200\n",
      "Processing batch from user 49200 to user 49300\n",
      "Processing batch from user 49300 to user 49400\n",
      "Processing batch from user 49400 to user 49500\n",
      "Processing batch from user 49500 to user 49600\n",
      "Processing batch from user 49600 to user 49700\n",
      "Processing batch from user 49700 to user 49800\n",
      "Processing batch from user 49800 to user 49900\n",
      "Processing batch from user 49900 to user 50000\n",
      "Processing batch from user 50000 to user 50100\n",
      "Processing batch from user 50100 to user 50200\n",
      "Processing batch from user 50200 to user 50300\n",
      "Processing batch from user 50300 to user 50400\n",
      "Processing batch from user 50400 to user 50500\n",
      "Processing batch from user 50500 to user 50600\n",
      "Processing batch from user 50600 to user 50700\n",
      "Processing batch from user 50700 to user 50800\n",
      "Processing batch from user 50800 to user 50900\n",
      "Processing batch from user 50900 to user 51000\n",
      "Processing batch from user 51000 to user 51100\n",
      "Processing batch from user 51100 to user 51200\n",
      "Processing batch from user 51200 to user 51300\n",
      "Processing batch from user 51300 to user 51400\n",
      "Processing batch from user 51400 to user 51500\n",
      "Processing batch from user 51500 to user 51600\n",
      "Processing batch from user 51600 to user 51700\n",
      "Processing batch from user 51700 to user 51800\n",
      "Processing batch from user 51800 to user 51900\n",
      "Processing batch from user 51900 to user 52000\n",
      "Processing batch from user 52000 to user 52100\n",
      "Processing batch from user 52100 to user 52200\n",
      "Processing batch from user 52200 to user 52300\n",
      "Processing batch from user 52300 to user 52400\n",
      "Processing batch from user 52400 to user 52500\n",
      "Processing batch from user 52500 to user 52600\n",
      "Processing batch from user 52600 to user 52700\n",
      "Processing batch from user 52700 to user 52800\n",
      "Processing batch from user 52800 to user 52900\n",
      "Processing batch from user 52900 to user 53000\n",
      "Processing batch from user 53000 to user 53100\n",
      "Processing batch from user 53100 to user 53200\n",
      "Processing batch from user 53200 to user 53300\n",
      "Processing batch from user 53300 to user 53400\n",
      "Processing batch from user 53400 to user 53500\n",
      "Processing batch from user 53500 to user 53600\n",
      "Processing batch from user 53600 to user 53700\n",
      "Processing batch from user 53700 to user 53800\n",
      "Processing batch from user 53800 to user 53900\n",
      "Processing batch from user 53900 to user 54000\n",
      "Processing batch from user 54000 to user 54100\n",
      "Processing batch from user 54100 to user 54200\n",
      "Processing batch from user 54200 to user 54300\n",
      "Processing batch from user 54300 to user 54400\n",
      "Processing batch from user 54400 to user 54500\n",
      "Processing batch from user 54500 to user 54600\n",
      "Processing batch from user 54600 to user 54700\n",
      "Processing batch from user 54700 to user 54800\n",
      "Processing batch from user 54800 to user 54900\n",
      "Processing batch from user 54900 to user 55000\n",
      "Processing batch from user 55000 to user 55100\n",
      "Processing batch from user 55100 to user 55200\n",
      "Processing batch from user 55200 to user 55300\n",
      "Processing batch from user 55300 to user 55400\n",
      "Processing batch from user 55400 to user 55500\n",
      "Processing batch from user 55500 to user 55600\n",
      "Processing batch from user 55600 to user 55700\n",
      "Processing batch from user 55700 to user 55800\n",
      "Processing batch from user 55800 to user 55900\n",
      "Processing batch from user 55900 to user 56000\n",
      "Processing batch from user 56000 to user 56100\n",
      "Processing batch from user 56100 to user 56200\n",
      "Processing batch from user 56200 to user 56300\n",
      "Processing batch from user 56300 to user 56400\n",
      "Processing batch from user 56400 to user 56500\n",
      "Processing batch from user 56500 to user 56600\n",
      "Processing batch from user 56600 to user 56700\n",
      "Processing batch from user 56700 to user 56800\n",
      "Processing batch from user 56800 to user 56900\n",
      "Processing batch from user 56900 to user 57000\n",
      "Processing batch from user 57000 to user 57100\n",
      "Processing batch from user 57100 to user 57200\n",
      "Processing batch from user 57200 to user 57300\n",
      "Processing batch from user 57300 to user 57400\n",
      "Processing batch from user 57400 to user 57500\n",
      "Processing batch from user 57500 to user 57600\n",
      "Processing batch from user 57600 to user 57700\n",
      "Processing batch from user 57700 to user 57800\n",
      "Processing batch from user 57800 to user 57900\n",
      "Processing batch from user 57900 to user 58000\n",
      "Processing batch from user 58000 to user 58100\n",
      "Processing batch from user 58100 to user 58200\n",
      "Processing batch from user 58200 to user 58300\n",
      "Processing batch from user 58300 to user 58400\n",
      "Processing batch from user 58400 to user 58500\n",
      "Processing batch from user 58500 to user 58600\n",
      "Processing batch from user 58600 to user 58700\n",
      "Processing batch from user 58700 to user 58800\n",
      "Processing batch from user 58800 to user 58900\n",
      "Processing batch from user 58900 to user 59000\n",
      "Processing batch from user 59000 to user 59100\n",
      "Processing batch from user 59100 to user 59200\n",
      "Processing batch from user 59200 to user 59300\n",
      "Processing batch from user 59300 to user 59400\n",
      "Processing batch from user 59400 to user 59500\n",
      "Processing batch from user 59500 to user 59600\n",
      "Processing batch from user 59600 to user 59700\n",
      "Processing batch from user 59700 to user 59800\n",
      "Processing batch from user 59800 to user 59900\n",
      "Processing batch from user 59900 to user 60000\n",
      "Processing batch from user 60000 to user 60100\n",
      "Processing batch from user 60100 to user 60200\n",
      "Processing batch from user 60200 to user 60300\n",
      "Processing batch from user 60300 to user 60400\n",
      "Processing batch from user 60400 to user 60500\n",
      "Processing batch from user 60500 to user 60600\n",
      "Processing batch from user 60600 to user 60700\n",
      "Processing batch from user 60700 to user 60800\n",
      "Processing batch from user 60800 to user 60900\n",
      "Processing batch from user 60900 to user 61000\n",
      "Processing batch from user 61000 to user 61100\n",
      "Processing batch from user 61100 to user 61200\n",
      "Processing batch from user 61200 to user 61300\n",
      "Processing batch from user 61300 to user 61400\n",
      "Processing batch from user 61400 to user 61500\n",
      "Processing batch from user 61500 to user 61600\n",
      "Processing batch from user 61600 to user 61700\n",
      "Processing batch from user 61700 to user 61800\n",
      "Processing batch from user 61800 to user 61900\n",
      "Processing batch from user 61900 to user 62000\n",
      "Processing batch from user 62000 to user 62100\n",
      "Processing batch from user 62100 to user 62200\n",
      "Processing batch from user 62200 to user 62300\n",
      "Processing batch from user 62300 to user 62400\n",
      "Processing batch from user 62400 to user 62500\n",
      "Processing batch from user 62500 to user 62600\n",
      "Processing batch from user 62600 to user 62700\n",
      "Processing batch from user 62700 to user 62800\n",
      "Processing batch from user 62800 to user 62900\n",
      "Processing batch from user 62900 to user 63000\n",
      "Processing batch from user 63000 to user 63100\n",
      "Processing batch from user 63100 to user 63200\n",
      "Processing batch from user 63200 to user 63300\n",
      "Processing batch from user 63300 to user 63400\n",
      "Processing batch from user 63400 to user 63500\n",
      "Processing batch from user 63500 to user 63600\n",
      "Processing batch from user 63600 to user 63700\n",
      "Processing batch from user 63700 to user 63800\n",
      "Processing batch from user 63800 to user 63900\n",
      "Processing batch from user 63900 to user 64000\n",
      "Processing batch from user 64000 to user 64100\n",
      "Processing batch from user 64100 to user 64200\n",
      "Processing batch from user 64200 to user 64300\n",
      "Processing batch from user 64300 to user 64400\n",
      "Processing batch from user 64400 to user 64500\n",
      "Processing batch from user 64500 to user 64600\n",
      "Processing batch from user 64600 to user 64700\n",
      "Processing batch from user 64700 to user 64800\n",
      "Processing batch from user 64800 to user 64900\n",
      "Processing batch from user 64900 to user 65000\n",
      "Processing batch from user 65000 to user 65100\n",
      "Processing batch from user 65100 to user 65200\n",
      "Processing batch from user 65200 to user 65300\n",
      "Processing batch from user 65300 to user 65400\n",
      "Processing batch from user 65400 to user 65500\n",
      "Processing batch from user 65500 to user 65600\n",
      "Processing batch from user 65600 to user 65700\n",
      "Processing batch from user 65700 to user 65800\n",
      "Processing batch from user 65800 to user 65900\n",
      "Processing batch from user 65900 to user 66000\n",
      "Processing batch from user 66000 to user 66100\n",
      "Processing batch from user 66100 to user 66200\n",
      "Processing batch from user 66200 to user 66300\n",
      "Processing batch from user 66300 to user 66400\n",
      "Processing batch from user 66400 to user 66500\n",
      "Processing batch from user 66500 to user 66600\n",
      "Processing batch from user 66600 to user 66700\n",
      "Processing batch from user 66700 to user 66800\n",
      "Processing batch from user 66800 to user 66900\n",
      "Processing batch from user 66900 to user 67000\n",
      "Processing batch from user 67000 to user 67100\n",
      "Processing batch from user 67100 to user 67200\n",
      "Processing batch from user 67200 to user 67300\n",
      "Processing batch from user 67300 to user 67400\n",
      "Processing batch from user 67400 to user 67500\n",
      "Processing batch from user 67500 to user 67600\n",
      "Processing batch from user 67600 to user 67700\n",
      "Processing batch from user 67700 to user 67800\n",
      "Processing batch from user 67800 to user 67900\n",
      "Processing batch from user 67900 to user 68000\n",
      "Processing batch from user 68000 to user 68100\n",
      "Processing batch from user 68100 to user 68200\n",
      "Processing batch from user 68200 to user 68300\n",
      "Processing batch from user 68300 to user 68400\n",
      "Processing batch from user 68400 to user 68500\n",
      "Processing batch from user 68500 to user 68600\n",
      "Processing batch from user 68600 to user 68700\n",
      "Processing batch from user 68700 to user 68800\n",
      "Processing batch from user 68800 to user 68900\n",
      "Processing batch from user 68900 to user 69000\n",
      "Processing batch from user 69000 to user 69100\n",
      "Processing batch from user 69100 to user 69200\n",
      "Processing batch from user 69200 to user 69300\n",
      "Processing batch from user 69300 to user 69400\n",
      "Processing batch from user 69400 to user 69500\n",
      "Processing batch from user 69500 to user 69600\n",
      "Processing batch from user 69600 to user 69700\n",
      "Processing batch from user 69700 to user 69800\n",
      "Processing batch from user 69800 to user 69900\n",
      "Processing batch from user 69900 to user 70000\n",
      "Processing batch from user 70000 to user 70100\n",
      "Processing batch from user 70100 to user 70200\n",
      "Processing batch from user 70200 to user 70300\n",
      "Processing batch from user 70300 to user 70400\n",
      "Processing batch from user 70400 to user 70500\n",
      "Processing batch from user 70500 to user 70600\n",
      "Processing batch from user 70600 to user 70700\n",
      "Processing batch from user 70700 to user 70800\n",
      "Processing batch from user 70800 to user 70900\n",
      "Processing batch from user 70900 to user 71000\n",
      "Processing batch from user 71000 to user 71100\n",
      "Processing batch from user 71100 to user 71200\n",
      "Processing batch from user 71200 to user 71300\n",
      "Processing batch from user 71300 to user 71400\n",
      "Processing batch from user 71400 to user 71500\n",
      "Processing batch from user 71500 to user 71600\n",
      "Processing batch from user 71600 to user 71700\n",
      "Processing batch from user 71700 to user 71800\n",
      "Processing batch from user 71800 to user 71900\n",
      "Processing batch from user 71900 to user 72000\n",
      "Processing batch from user 72000 to user 72100\n",
      "Processing batch from user 72100 to user 72200\n",
      "Processing batch from user 72200 to user 72300\n",
      "Processing batch from user 72300 to user 72400\n",
      "Processing batch from user 72400 to user 72500\n",
      "Processing batch from user 72500 to user 72600\n",
      "Processing batch from user 72600 to user 72700\n",
      "Processing batch from user 72700 to user 72800\n",
      "Processing batch from user 72800 to user 72900\n",
      "Processing batch from user 72900 to user 73000\n",
      "Processing batch from user 73000 to user 73100\n",
      "Processing batch from user 73100 to user 73200\n",
      "Processing batch from user 73200 to user 73300\n",
      "Processing batch from user 73300 to user 73400\n",
      "Processing batch from user 73400 to user 73500\n",
      "Processing batch from user 73500 to user 73600\n",
      "Processing batch from user 73600 to user 73700\n",
      "Processing batch from user 73700 to user 73800\n",
      "Processing batch from user 73800 to user 73900\n",
      "Processing batch from user 73900 to user 74000\n",
      "Processing batch from user 74000 to user 74100\n",
      "Processing batch from user 74100 to user 74200\n",
      "Processing batch from user 74200 to user 74300\n",
      "Processing batch from user 74300 to user 74400\n",
      "Processing batch from user 74400 to user 74500\n",
      "Processing batch from user 74500 to user 74600\n",
      "Processing batch from user 74600 to user 74700\n",
      "Processing batch from user 74700 to user 74800\n",
      "Processing batch from user 74800 to user 74900\n",
      "Processing batch from user 74900 to user 75000\n",
      "Processing batch from user 75000 to user 75100\n",
      "Processing batch from user 75100 to user 75200\n",
      "Processing batch from user 75200 to user 75300\n",
      "Processing batch from user 75300 to user 75400\n",
      "Processing batch from user 75400 to user 75500\n",
      "Processing batch from user 75500 to user 75600\n",
      "Processing batch from user 75600 to user 75700\n",
      "Processing batch from user 75700 to user 75800\n",
      "Processing batch from user 75800 to user 75900\n",
      "Processing batch from user 75900 to user 76000\n",
      "Processing batch from user 76000 to user 76100\n",
      "Processing batch from user 76100 to user 76200\n",
      "Processing batch from user 76200 to user 76300\n",
      "Processing batch from user 76300 to user 76400\n",
      "Processing batch from user 76400 to user 76500\n",
      "Processing batch from user 76500 to user 76600\n",
      "Processing batch from user 76600 to user 76700\n",
      "Processing batch from user 76700 to user 76800\n",
      "Processing batch from user 76800 to user 76900\n",
      "Processing batch from user 76900 to user 77000\n",
      "Processing batch from user 77000 to user 77100\n",
      "Processing batch from user 77100 to user 77200\n",
      "Processing batch from user 77200 to user 77300\n",
      "Processing batch from user 77300 to user 77400\n",
      "Processing batch from user 77400 to user 77500\n",
      "Processing batch from user 77500 to user 77600\n",
      "Processing batch from user 77600 to user 77700\n",
      "Processing batch from user 77700 to user 77800\n",
      "Processing batch from user 77800 to user 77900\n",
      "Processing batch from user 77900 to user 78000\n",
      "Processing batch from user 78000 to user 78100\n",
      "Processing batch from user 78100 to user 78200\n",
      "Processing batch from user 78200 to user 78300\n",
      "Processing batch from user 78300 to user 78400\n",
      "Processing batch from user 78400 to user 78500\n",
      "Processing batch from user 78500 to user 78600\n",
      "Processing batch from user 78600 to user 78700\n",
      "Processing batch from user 78700 to user 78800\n",
      "Processing batch from user 78800 to user 78900\n",
      "Processing batch from user 78900 to user 79000\n",
      "Processing batch from user 79000 to user 79100\n",
      "Processing batch from user 79100 to user 79200\n",
      "Processing batch from user 79200 to user 79300\n",
      "Processing batch from user 79300 to user 79400\n",
      "Processing batch from user 79400 to user 79500\n",
      "Processing batch from user 79500 to user 79600\n",
      "Processing batch from user 79600 to user 79700\n",
      "Processing batch from user 79700 to user 79800\n",
      "Processing batch from user 79800 to user 79900\n",
      "Processing batch from user 79900 to user 80000\n",
      "Processing batch from user 80000 to user 80100\n",
      "Processing batch from user 80100 to user 80200\n",
      "Processing batch from user 80200 to user 80300\n",
      "Processing batch from user 80300 to user 80400\n",
      "Processing batch from user 80400 to user 80500\n",
      "Processing batch from user 80500 to user 80600\n",
      "Processing batch from user 80600 to user 80700\n",
      "Processing batch from user 80700 to user 80800\n",
      "Processing batch from user 80800 to user 80900\n",
      "Processing batch from user 80900 to user 81000\n",
      "Processing batch from user 81000 to user 81100\n",
      "Processing batch from user 81100 to user 81200\n",
      "Processing batch from user 81200 to user 81300\n",
      "Processing batch from user 81300 to user 81400\n",
      "Processing batch from user 81400 to user 81500\n",
      "Processing batch from user 81500 to user 81600\n",
      "Processing batch from user 81600 to user 81700\n",
      "Processing batch from user 81700 to user 81800\n",
      "Processing batch from user 81800 to user 81900\n",
      "Processing batch from user 81900 to user 82000\n",
      "Processing batch from user 82000 to user 82100\n",
      "Processing batch from user 82100 to user 82200\n",
      "Processing batch from user 82200 to user 82300\n",
      "Processing batch from user 82300 to user 82400\n",
      "Processing batch from user 82400 to user 82500\n",
      "Processing batch from user 82500 to user 82600\n",
      "Processing batch from user 82600 to user 82700\n",
      "Processing batch from user 82700 to user 82800\n",
      "Processing batch from user 82800 to user 82900\n",
      "Processing batch from user 82900 to user 83000\n",
      "Processing batch from user 83000 to user 83100\n",
      "Processing batch from user 83100 to user 83200\n",
      "Processing batch from user 83200 to user 83300\n",
      "Processing batch from user 83300 to user 83400\n",
      "Processing batch from user 83400 to user 83500\n",
      "Processing batch from user 83500 to user 83600\n",
      "Processing batch from user 83600 to user 83700\n",
      "Processing batch from user 83700 to user 83800\n",
      "Processing batch from user 83800 to user 83900\n",
      "Processing batch from user 83900 to user 84000\n",
      "Processing batch from user 84000 to user 84100\n",
      "Processing batch from user 84100 to user 84200\n",
      "Processing batch from user 84200 to user 84300\n",
      "Processing batch from user 84300 to user 84400\n",
      "Processing batch from user 84400 to user 84500\n",
      "Processing batch from user 84500 to user 84600\n",
      "Processing batch from user 84600 to user 84700\n",
      "Processing batch from user 84700 to user 84800\n",
      "Processing batch from user 84800 to user 84900\n",
      "Processing batch from user 84900 to user 85000\n",
      "Processing batch from user 85000 to user 85100\n",
      "Processing batch from user 85100 to user 85200\n",
      "Processing batch from user 85200 to user 85300\n",
      "Processing batch from user 85300 to user 85400\n",
      "Processing batch from user 85400 to user 85500\n",
      "Processing batch from user 85500 to user 85600\n",
      "Processing batch from user 85600 to user 85700\n",
      "Processing batch from user 85700 to user 85800\n",
      "Processing batch from user 85800 to user 85900\n",
      "Processing batch from user 85900 to user 86000\n",
      "Processing batch from user 86000 to user 86100\n",
      "Processing batch from user 86100 to user 86200\n",
      "Processing batch from user 86200 to user 86300\n",
      "Processing batch from user 86300 to user 86400\n",
      "Processing batch from user 86400 to user 86500\n",
      "Processing batch from user 86500 to user 86600\n",
      "Processing batch from user 86600 to user 86700\n",
      "Processing batch from user 86700 to user 86800\n",
      "Processing batch from user 86800 to user 86900\n",
      "Processing batch from user 86900 to user 87000\n",
      "Processing batch from user 87000 to user 87100\n",
      "Processing batch from user 87100 to user 87200\n",
      "Processing batch from user 87200 to user 87300\n",
      "Processing batch from user 87300 to user 87400\n",
      "Processing batch from user 87400 to user 87500\n",
      "Processing batch from user 87500 to user 87600\n",
      "Processing batch from user 87600 to user 87700\n",
      "Processing batch from user 87700 to user 87800\n",
      "Processing batch from user 87800 to user 87900\n",
      "Processing batch from user 87900 to user 88000\n",
      "Processing batch from user 88000 to user 88100\n",
      "Processing batch from user 88100 to user 88200\n",
      "Processing batch from user 88200 to user 88300\n",
      "Processing batch from user 88300 to user 88400\n",
      "Processing batch from user 88400 to user 88500\n",
      "Processing batch from user 88500 to user 88600\n",
      "Processing batch from user 88600 to user 88700\n",
      "Processing batch from user 88700 to user 88800\n",
      "Processing batch from user 88800 to user 88900\n",
      "Processing batch from user 88900 to user 89000\n",
      "Processing batch from user 89000 to user 89100\n",
      "Processing batch from user 89100 to user 89200\n",
      "Processing batch from user 89200 to user 89300\n",
      "Processing batch from user 89300 to user 89400\n",
      "Processing batch from user 89400 to user 89500\n",
      "Processing batch from user 89500 to user 89600\n",
      "Processing batch from user 89600 to user 89700\n",
      "Processing batch from user 89700 to user 89800\n",
      "Processing batch from user 89800 to user 89900\n",
      "Processing batch from user 89900 to user 90000\n",
      "Processing batch from user 90000 to user 90100\n",
      "Processing batch from user 90100 to user 90200\n",
      "Processing batch from user 90200 to user 90300\n",
      "Processing batch from user 90300 to user 90400\n",
      "Processing batch from user 90400 to user 90500\n",
      "Processing batch from user 90500 to user 90600\n",
      "Processing batch from user 90600 to user 90700\n",
      "Processing batch from user 90700 to user 90800\n",
      "Processing batch from user 90800 to user 90900\n",
      "Processing batch from user 90900 to user 91000\n",
      "Processing batch from user 91000 to user 91100\n",
      "Processing batch from user 91100 to user 91200\n",
      "Processing batch from user 91200 to user 91300\n",
      "Processing batch from user 91300 to user 91400\n",
      "Processing batch from user 91400 to user 91500\n",
      "Processing batch from user 91500 to user 91600\n",
      "Processing batch from user 91600 to user 91700\n",
      "Processing batch from user 91700 to user 91800\n",
      "Processing batch from user 91800 to user 91900\n",
      "Processing batch from user 91900 to user 92000\n",
      "Processing batch from user 92000 to user 92100\n",
      "Processing batch from user 92100 to user 92200\n",
      "Processing batch from user 92200 to user 92300\n",
      "Processing batch from user 92300 to user 92400\n",
      "Processing batch from user 92400 to user 92500\n",
      "Processing batch from user 92500 to user 92600\n",
      "Processing batch from user 92600 to user 92700\n",
      "Processing batch from user 92700 to user 92800\n",
      "Processing batch from user 92800 to user 92900\n",
      "Processing batch from user 92900 to user 93000\n",
      "Processing batch from user 93000 to user 93100\n",
      "Processing batch from user 93100 to user 93200\n",
      "Processing batch from user 93200 to user 93300\n",
      "Processing batch from user 93300 to user 93400\n",
      "Processing batch from user 93400 to user 93500\n",
      "Processing batch from user 93500 to user 93600\n",
      "Processing batch from user 93600 to user 93700\n",
      "Processing batch from user 93700 to user 93800\n",
      "Processing batch from user 93800 to user 93900\n",
      "Processing batch from user 93900 to user 94000\n",
      "Processing batch from user 94000 to user 94100\n",
      "Processing batch from user 94100 to user 94200\n",
      "Processing batch from user 94200 to user 94300\n",
      "Processing batch from user 94300 to user 94400\n",
      "Processing batch from user 94400 to user 94500\n",
      "Processing batch from user 94500 to user 94600\n",
      "Processing batch from user 94600 to user 94700\n",
      "Processing batch from user 94700 to user 94800\n",
      "Processing batch from user 94800 to user 94900\n",
      "Processing batch from user 94900 to user 95000\n",
      "Processing batch from user 95000 to user 95100\n",
      "Processing batch from user 95100 to user 95200\n",
      "Processing batch from user 95200 to user 95300\n",
      "Processing batch from user 95300 to user 95400\n",
      "Processing batch from user 95400 to user 95500\n",
      "Processing batch from user 95500 to user 95600\n",
      "Processing batch from user 95600 to user 95700\n",
      "Processing batch from user 95700 to user 95800\n",
      "Processing batch from user 95800 to user 95900\n",
      "Processing batch from user 95900 to user 96000\n",
      "Processing batch from user 96000 to user 96100\n",
      "Processing batch from user 96100 to user 96200\n",
      "Processing batch from user 96200 to user 96300\n",
      "Processing batch from user 96300 to user 96400\n",
      "Processing batch from user 96400 to user 96500\n",
      "Processing batch from user 96500 to user 96600\n",
      "Processing batch from user 96600 to user 96700\n",
      "Processing batch from user 96700 to user 96800\n",
      "Processing batch from user 96800 to user 96900\n",
      "Processing batch from user 96900 to user 97000\n",
      "Processing batch from user 97000 to user 97100\n",
      "Processing batch from user 97100 to user 97200\n",
      "Processing batch from user 97200 to user 97300\n",
      "Processing batch from user 97300 to user 97400\n",
      "Processing batch from user 97400 to user 97500\n",
      "Processing batch from user 97500 to user 97600\n",
      "Processing batch from user 97600 to user 97700\n",
      "Processing batch from user 97700 to user 97800\n",
      "Processing batch from user 97800 to user 97900\n",
      "Processing batch from user 97900 to user 98000\n",
      "Processing batch from user 98000 to user 98100\n",
      "Processing batch from user 98100 to user 98200\n",
      "Processing batch from user 98200 to user 98300\n",
      "Processing batch from user 98300 to user 98400\n",
      "Processing batch from user 98400 to user 98500\n",
      "Processing batch from user 98500 to user 98600\n",
      "Processing batch from user 98600 to user 98700\n",
      "Processing batch from user 98700 to user 98800\n",
      "Processing batch from user 98800 to user 98900\n",
      "Processing batch from user 98900 to user 99000\n",
      "Processing batch from user 99000 to user 99100\n",
      "Processing batch from user 99100 to user 99200\n",
      "Processing batch from user 99200 to user 99300\n",
      "Processing batch from user 99300 to user 99400\n",
      "Processing batch from user 99400 to user 99500\n",
      "Processing batch from user 99500 to user 99600\n",
      "Processing batch from user 99600 to user 99700\n",
      "Processing batch from user 99700 to user 99800\n",
      "Processing batch from user 99800 to user 99900\n",
      "Processing batch from user 99900 to user 100000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "from scipy.sparse import save_npz\n",
    "\n",
    "\n",
    "# Step 3: Calculate User-User Similarity Matrix in Smaller Batches\n",
    "num_users = user_item_sparse_matrix.shape[0]\n",
    "batch_size = 100  # Small batch size to avoid kernel crash\n",
    "\n",
    "# Initialize an empty list to store similarity results in chunks\n",
    "similarity_rows = []\n",
    "\n",
    "for start in range(0, num_users, batch_size):\n",
    "    end = min(start + batch_size, num_users)\n",
    "    print(f\"Processing batch from user {start} to user {end}\")\n",
    "\n",
    "    # Calculate similarity for the current batch against all users (in sparse form)\n",
    "    batch_similarity = cosine_similarity(user_item_sparse_matrix[start:end], user_item_sparse_matrix, dense_output=False)\n",
    "    similarity_rows.append(csr_matrix(batch_similarity))  # Convert to CSR format if not already\n",
    "\n",
    "# Stack all the batches to form the complete user similarity matrix (still sparse)\n",
    "user_similarity_matrix_sparse = vstack(similarity_rows)\n",
    "\n",
    "# Optional: Save the similarity matrix for later use\n",
    "# You can use scipy's save_npz method to save sparse matrices\n",
    "save_npz('user_similarity_matrix.npz', user_similarity_matrix_sparse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rzz50U4BuLeO",
    "outputId": "1ef31d77-d7de-4574-cb85-a35da4eddbe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 similar users to user 88813:\n",
      "91476    0.707107\n",
      "59800    0.500000\n",
      "74779    0.408248\n",
      "82316    0.316228\n",
      "94527    0.288675\n",
      "85429    0.250000\n",
      "12301    0.144338\n",
      "73753    0.107833\n",
      "66669    0.000000\n",
      "66668    0.000000\n",
      "Name: 88813, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import load_npz\n",
    "\n",
    "# Load the saved user similarity matrix (assuming it's stored in sparse format)\n",
    "user_similarity_matrix_sparse = load_npz('user_similarity_matrix.npz')\n",
    "\n",
    "# Example: Find similar users for a specific user ID\n",
    "user_id = 88813\n",
    "\n",
    "if user_id in range(user_similarity_matrix_sparse.shape[0]):\n",
    "    # Convert the sparse row to a dense array and create a DataFrame for easier manipulation\n",
    "    user_similarity_df = pd.DataFrame(user_similarity_matrix_sparse.toarray(), index=range(user_similarity_matrix_sparse.shape[0]))\n",
    "\n",
    "    similar_users = user_similarity_df.loc[user_id].sort_values(ascending=False).drop(user_id).head(10)\n",
    "    print(f\"Top 10 similar users to user {user_id}:\\n{similar_users}\")\n",
    "else:\n",
    "    print(f\"User {user_id} not found in the similarity matrix.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eu942_abuLhG",
    "outputId": "d84a309b-ded0-4432-9264-fa9cf3da3ac1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 similar users to user 1000:\n",
      "41406    0.500000\n",
      "78385    0.500000\n",
      "84295    0.500000\n",
      "13385    0.353553\n",
      "2291     0.353553\n",
      "62907    0.353553\n",
      "5064     0.353553\n",
      "84053    0.288675\n",
      "83762    0.288675\n",
      "74968    0.288675\n",
      "Name: 1000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Example: Find similar users for a specific user ID\n",
    "user_id = 1000\n",
    "\n",
    "if user_id in range(user_similarity_matrix_sparse.shape[0]):\n",
    "    # Convert the sparse row to a dense array and create a DataFrame for easier manipulation\n",
    "    user_similarity_df = pd.DataFrame(user_similarity_matrix_sparse.toarray(), index=range(user_similarity_matrix_sparse.shape[0]))\n",
    "\n",
    "    similar_users = user_similarity_df.loc[user_id].sort_values(ascending=False).drop(user_id).head(10)\n",
    "    print(f\"Top 10 similar users to user {user_id}:\\n{similar_users}\")\n",
    "else:\n",
    "    print(f\"User {user_id} not found in the similarity matrix.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k5dqp7S5uLkO",
    "outputId": "5df58134-8453-432f-9be4-f371b3b42bbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 similar users to user 2870:\n",
      "58978    0.707107\n",
      "93607    0.500000\n",
      "75443    0.408248\n",
      "66671    0.000000\n",
      "66669    0.000000\n",
      "66668    0.000000\n",
      "66667    0.000000\n",
      "66666    0.000000\n",
      "66665    0.000000\n",
      "66664    0.000000\n",
      "Name: 2870, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Example: Find similar users for a specific user ID\n",
    "user_id = 2870\n",
    "\n",
    "if user_id in range(user_similarity_matrix_sparse.shape[0]):\n",
    "    # Convert the sparse row to a dense array and create a DataFrame for easier manipulation\n",
    "    user_similarity_df = pd.DataFrame(user_similarity_matrix_sparse.toarray(), index=range(user_similarity_matrix_sparse.shape[0]))\n",
    "\n",
    "    similar_users = user_similarity_df.loc[user_id].sort_values(ascending=False).drop(user_id).head(10)\n",
    "    print(f\"Top 10 similar users to user {user_id}:\\n{similar_users}\")\n",
    "else:\n",
    "    print(f\"User {user_id} not found in the similarity matrix.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r-WN103auLm0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "koAKj_k9uLpc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFH4ZGLjR5pk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eJgVXOBR6a7"
   },
   "source": [
    "# Hybrid Recommendation System\n",
    "### Content Based Filtering & Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8DpWNbFosQ-"
   },
   "source": [
    "with Additional Handling\n",
    "\n",
    "No Liked Products:\n",
    "If the user has no liked products, we immediately provide the top popular seasonal products based on frequency in product_df.\n",
    "\n",
    "No Seasonal Products Based on Preferences:\n",
    "After attempting collaborative and content-based filtering, if no relevant seasonal products are found, we fallback to popular items for the current season.\n",
    "\n",
    "Final Check:\n",
    "If the recommendations list is still empty by the end, a final fallback provides the top popular seasonal products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1gqTMGtJRTcj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "# Assuming customer_df, product_df, similarity_df, and user_similarity_matrix_sparse are already defined.\n",
    "\n",
    "# Load the user similarity matrix\n",
    "user_similarity_matrix_sparse = load_npz('user_similarity_matrix.npz')\n",
    "user_similarity_df = pd.DataFrame(user_similarity_matrix_sparse.toarray(), index=customer_df['customer_id'], columns=customer_df['customer_id'])\n",
    "\n",
    "# Function to determine the current season\n",
    "def determine_season():\n",
    "    # For simplicity, we return a fixed value for the season.\n",
    "    # You can replace this logic with a real-time approach if needed.\n",
    "    return 'Summer'\n",
    "\n",
    "# Function to get similar users for a given user_id\n",
    "def get_similar_users(user_id, top_n=5):\n",
    "    if user_id in user_similarity_df.index:\n",
    "        similar_users = user_similarity_df.loc[user_id].sort_values(ascending=False).drop(user_id).head(top_n).index.tolist()\n",
    "        return similar_users\n",
    "    else:\n",
    "        print(f\"User {user_id} not found in the similarity matrix.\")\n",
    "        return []\n",
    "\n",
    "# Function to get hybrid recommendations for a user\n",
    "def get_recommendations(user_id, top_n=10):\n",
    "    recommendations = []\n",
    "\n",
    "    # Get the user's liked products\n",
    "    user_data = customer_df[customer_df['customer_id'] == user_id]\n",
    "    if user_data.empty:\n",
    "        print(f\"User {user_id} not found in customer_df. Returning empty recommendations.\")\n",
    "        return recommendations  # Return empty if user not found\n",
    "\n",
    "    liked_products = user_data['past_trans'].values[0]\n",
    "    liked_products = ast.literal_eval(liked_products) if isinstance(liked_products, str) else liked_products\n",
    "\n",
    "    # If no liked products are found, provide a default list of popular seasonal products\n",
    "    current_season = determine_season()\n",
    "    if not liked_products:\n",
    "        print(f\"No liked products found for user {user_id}. Returning popular seasonal products.\")\n",
    "        seasonal_popular = product_df[product_df['season'] == current_season]['id'].value_counts().index.tolist()\n",
    "\n",
    "        # Assign exponential decay scores based on rank (higher rank gets higher score)\n",
    "        total_products = len(seasonal_popular)\n",
    "        decay_factor = 0.9  # Adjust decay factor to control how fast the score decreases\n",
    "        recommendations = [\n",
    "            {\n",
    "                'customer_id': user_id,\n",
    "                'product_id': product,\n",
    "                'rank_score': decay_factor ** idx  # Exponentially decaying score\n",
    "            }\n",
    "            for idx, product in enumerate(seasonal_popular[:top_n])\n",
    "        ]\n",
    "\n",
    "        return recommendations\n",
    "\n",
    "    print(f\"Liked products for user {user_id}: {liked_products}\")\n",
    "\n",
    "    # Get similar users\n",
    "    similar_users = get_similar_users(user_id, top_n=5)\n",
    "    similar_users_liked_products = []\n",
    "    similar_users_scores = []\n",
    "\n",
    "    if similar_users:\n",
    "        # Get products liked by similar users and their corresponding similarity scores\n",
    "        for similar_user in similar_users:\n",
    "            similarity_score = user_similarity_df.loc[user_id, similar_user]\n",
    "            similar_user_products = customer_df[customer_df['customer_id'] == similar_user]['past_trans'].values[0]\n",
    "            similar_user_products = ast.literal_eval(similar_user_products) if isinstance(similar_user_products, str) else similar_user_products\n",
    "            similar_users_liked_products.extend(similar_user_products)\n",
    "            similar_users_scores.extend([similarity_score] * len(similar_user_products))\n",
    "\n",
    "    print(f\"Products liked by similar users for user {user_id}: {similar_users_liked_products}\")\n",
    "\n",
    "    # Get products similar to what the user liked\n",
    "    similar_products = similarity_df[similarity_df['product_id'].isin(liked_products)]\n",
    "    similar_products_ids = similar_products['similar_product_id'].tolist()\n",
    "    similar_products_scores = similar_products['distance'].tolist()  # Assuming smaller distance means higher similarity\n",
    "\n",
    "    print(f\"Products similar to liked products for user {user_id}: {similar_products_ids}\")\n",
    "\n",
    "    # Determine the current season\n",
    "    print(f\"Current season: {current_season}\")\n",
    "\n",
    "    # Filter recommendations by season\n",
    "    seasonal_products = product_df[product_df['id'].isin(similar_products_ids + similar_users_liked_products) &\n",
    "                                   (product_df['season'] == current_season)]\n",
    "\n",
    "    if seasonal_products.empty:\n",
    "        print(f\"No seasonal products found for user {user_id}'s preferences. Returning popular items in season.\")\n",
    "        seasonal_products = product_df[product_df['season'] == current_season].head(top_n)\n",
    "\n",
    "    # Aggregate scores for products\n",
    "    product_scores = {}\n",
    "\n",
    "    # Add scores from similar users' liked products\n",
    "    for product_id, score in zip(similar_users_liked_products, similar_users_scores):\n",
    "        if product_id in seasonal_products['id'].values:\n",
    "            product_scores[product_id] = product_scores.get(product_id, 0) + score\n",
    "\n",
    "    # Add scores from similar products\n",
    "    for product_id, score in zip(similar_products_ids, similar_products_scores):\n",
    "        if product_id in seasonal_products['id'].values:\n",
    "            # Using inverse distance as a similarity score (since smaller distance means higher similarity)\n",
    "            similarity_score = 1 / (1 + score)\n",
    "            product_scores[product_id] = product_scores.get(product_id, 0) + similarity_score\n",
    "\n",
    "    # Normalize the scores to be between 0 and 1\n",
    "    max_score = max(product_scores.values()) if product_scores else 1\n",
    "    for product_id in product_scores:\n",
    "        product_scores[product_id] /= max_score\n",
    "\n",
    "    # Sort products by their aggregated scores in descending order and select the top N\n",
    "    ranked_products = sorted(product_scores.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "    # Prepare the recommendation list for the user\n",
    "    recommendations = [{'customer_id': user_id, 'product_id': product_id, 'rank_score': rank_score}\n",
    "                       for product_id, rank_score in ranked_products]\n",
    "\n",
    "    # Check if recommendations list is still empty, and if so, use fallback seasonal popular items\n",
    "    if not recommendations:\n",
    "        print(f\"No recommendations found based on preferences for user {user_id}. Using popular seasonal products.\")\n",
    "        seasonal_popular = product_df[product_df['season'] == current_season]['id'].value_counts().index.tolist()\n",
    "\n",
    "        # Assign exponential decay scores based on rank (higher rank gets higher score)\n",
    "        total_products = len(seasonal_popular)\n",
    "        decay_factor = 0.9  # Adjust decay factor to control how fast the score decreases\n",
    "        recommendations = [\n",
    "            {\n",
    "                'customer_id': user_id,\n",
    "                'product_id': product,\n",
    "                'rank_score': decay_factor ** idx  # Exponentially decaying score\n",
    "            }\n",
    "            for idx, product in enumerate(seasonal_popular[:top_n])\n",
    "        ]\n",
    "\n",
    "    # Convert recommendations to DataFrame and save to CSV\n",
    "    recommendations_df = pd.DataFrame(recommendations)\n",
    "    csv_filename = f'{user_id}_user_recommendations_{current_season}.csv'\n",
    "    recommendations_df.to_csv(csv_filename, index=False)\n",
    "\n",
    "    print(f\"Recommendations for user {user_id} saved to {csv_filename}.\")\n",
    "    print(\"Generated Recommendations:\", recommendations)\n",
    "\n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "# Load the user similarity matrix\n",
    "user_similarity_matrix_sparse = load_npz('user_similarity_matrix.npz')\n",
    "user_similarity_df = pd.DataFrame(user_similarity_matrix_sparse.toarray(), index=customer_df['customer_id'], columns=customer_df['customer_id'])\n",
    "\n",
    "# Function to determine the current season based on real-time weather and location\n",
    "def determine_season():\n",
    "    # Set up API keys (replace with your actual keys)\n",
    "    ipinfo_api_key = \"396370bd35a8161a2935f7cb0bd378a9\"  # positionstack.com\n",
    "    weather_api_key = \"5d8f488d96447f74ae5a04a7a41eaff3\" # openweathermap.org\n",
    "    \n",
    "    # Step 1: Get the user's approximate location using IPinfo\n",
    "    location_url = f\"https://ipinfo.io?token={ipinfo_api_key}\"\n",
    "    location_response = requests.get(location_url)\n",
    "    location_data = location_response.json()\n",
    "    \n",
    "    if 'loc' not in location_data:\n",
    "        print(\"Could not determine location. Defaulting to 'Summer'.\")\n",
    "        return 'Summer'  # Default season if location fetch fails\n",
    "\n",
    "    latitude, longitude = map(float, location_data['loc'].split(','))\n",
    "\n",
    "    # Step 2: Get real-time weather data using OpenWeatherMap\n",
    "    weather_url = f\"http://api.openweathermap.org/data/2.5/weather?lat={latitude}&lon={longitude}&appid={weather_api_key}\"\n",
    "    weather_response = requests.get(weather_url)\n",
    "    weather_data = weather_response.json()\n",
    "\n",
    "    # Extract temperature in Celsius\n",
    "    temperature_k = weather_data['main']['temp']\n",
    "    temperature_c = temperature_k - 273.15\n",
    "\n",
    "    # Basic logic to determine season based on temperature\n",
    "    if temperature_c > 25:\n",
    "        season = 'Summer'\n",
    "    elif 15 <= temperature_c <= 25:\n",
    "        season = 'Spring' if weather_data['weather'][0]['main'] in ['Clear', 'Rain'] else 'Fall'\n",
    "    else:\n",
    "        season = 'Winter'\n",
    "\n",
    "    print(f\"Determined season based on real-time data: {season}\")\n",
    "    return season\n",
    "\n",
    "# Function to get similar users for a given user_id\n",
    "def get_similar_users(user_id, top_n=5):\n",
    "    if user_id in user_similarity_df.index:\n",
    "        similar_users = user_similarity_df.loc[user_id].sort_values(ascending=False).drop(user_id).head(top_n).index.tolist()\n",
    "        return similar_users\n",
    "    else:\n",
    "        print(f\"User {user_id} not found in the similarity matrix.\")\n",
    "        return []\n",
    "\n",
    "# Function to get hybrid recommendations for a user\n",
    "def get_recommendations(user_id, top_n=10):\n",
    "    recommendations = []\n",
    "\n",
    "    # Get the user's liked products\n",
    "    user_data = customer_df[customer_df['customer_id'] == user_id]\n",
    "    if user_data.empty:\n",
    "        print(f\"User {user_id} not found in customer_df. Returning empty recommendations.\")\n",
    "        return recommendations  # Return empty if user not found\n",
    "\n",
    "    liked_products = user_data['past_trans'].values[0]\n",
    "    liked_products = ast.literal_eval(liked_products) if isinstance(liked_products, str) else liked_products\n",
    "\n",
    "    # If no liked products are found, provide a default list of popular seasonal products\n",
    "    current_season = determine_season()\n",
    "    if not liked_products:\n",
    "        print(f\"No liked products found for user {user_id}. Returning popular seasonal products.\")\n",
    "        seasonal_popular = product_df[product_df['season'] == current_season]['id'].value_counts().index.tolist()\n",
    "\n",
    "        # Assign exponential decay scores based on rank (higher rank gets higher score)\n",
    "        decay_factor = 0.9\n",
    "        recommendations = [\n",
    "            {'customer_id': user_id, 'product_id': product, 'rank_score': decay_factor ** idx}\n",
    "            for idx, product in enumerate(seasonal_popular[:top_n])\n",
    "        ]\n",
    "        return recommendations\n",
    "\n",
    "    # Remaining code for collaborative and content-based filtering follows...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mX0mONPpRvsE"
   },
   "source": [
    "## Rank Score\n",
    "\n",
    "To make the rank scores more meaningfully distributed across a wider range (e.g., between 0 and 1 with more significant variations), we can use a different scaling approach. Here are some options:\n",
    "\n",
    "- Linear Scaling with a Larger Adjustment: Instead of using the formula directly, we can scale the index values differently to spread them more evenly.\n",
    "\n",
    "- Exponential Decay: Use an exponential decay function to give a sharper difference between higher and lower-ranked products.\n",
    "    + The rank score for each product is calculated using an exponential decay function (decay_factor ** idx). The decay_factor is set to 0.9, which means the scores decrease exponentially with increasing rank.\n",
    "    + This approach ensures that products ranked higher receive significantly higher scores, and the scores decrease faster compared to linear scaling.\n",
    "    + Adjust Decay Factor: You can adjust the decay_factor to control the rate of decrease. A value closer to 1 (e.g., 0.95) will result in a slower decrease, while a smaller value (e.g., 0.7) will result in a faster decrease in scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H4QvvIDgRS_3",
    "outputId": "0f7ec446-1f59-47cc-a805-bf3a1c0c3a3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No liked products found for user 88813. Returning popular seasonal products.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'customer_id': 88813, 'product_id': 6461, 'rank_score': 1.0},\n",
       " {'customer_id': 88813, 'product_id': 39386, 'rank_score': 0.9},\n",
       " {'customer_id': 88813, 'product_id': 53759, 'rank_score': 0.81},\n",
       " {'customer_id': 88813, 'product_id': 1855, 'rank_score': 0.7290000000000001},\n",
       " {'customer_id': 88813, 'product_id': 24442, 'rank_score': 0.6561},\n",
       " {'customer_id': 88813, 'product_id': 40107, 'rank_score': 0.5904900000000001},\n",
       " {'customer_id': 88813, 'product_id': 3577, 'rank_score': 0.531441},\n",
       " {'customer_id': 88813, 'product_id': 42650, 'rank_score': 0.4782969000000001},\n",
       " {'customer_id': 88813, 'product_id': 30270, 'rank_score': 0.4304672100000001},\n",
       " {'customer_id': 88813, 'product_id': 54735, 'rank_score': 0.3874204890000001}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "user_id = 88813  # Replace with the actual user ID\n",
    "get_recommendations(user_id, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hd1Cn6v2uLvJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_xo0ZIQU6NZ"
   },
   "source": [
    "## Generate 4 CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "yeSoMmvBUzQ0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "# Assuming customer_df, product_df, similarity_df, and user_similarity_matrix_sparse are already defined.\n",
    "\n",
    "# Load the user similarity matrix\n",
    "user_similarity_matrix_sparse = load_npz('user_similarity_matrix.npz')\n",
    "user_similarity_df = pd.DataFrame(user_similarity_matrix_sparse.toarray(), index=customer_df['customer_id'], columns=customer_df['customer_id'])\n",
    "\n",
    "# Function to determine the current season\n",
    "# We'll iterate over each of the four seasons: 'Spring', 'Summer', 'Fall', 'Winter'\n",
    "def determine_season(season):\n",
    "    return season\n",
    "\n",
    "# Function to get similar users for a given user_id\n",
    "def get_similar_users(user_id, top_n=5):\n",
    "    if user_id in user_similarity_df.index:\n",
    "        similar_users = user_similarity_df.loc[user_id].sort_values(ascending=False).drop(user_id).head(top_n).index.tolist()\n",
    "        return similar_users\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Function to get hybrid recommendations for a user\n",
    "def get_recommendations(user_id, current_season, top_n=10):\n",
    "    recommendations = []\n",
    "\n",
    "    # Get the user's liked products\n",
    "    user_data = customer_df[customer_df['customer_id'] == user_id]\n",
    "    if user_data.empty:\n",
    "        return recommendations  # Return empty if user not found\n",
    "\n",
    "    liked_products = user_data['past_trans'].values[0]\n",
    "    liked_products = ast.literal_eval(liked_products) if isinstance(liked_products, str) else liked_products\n",
    "\n",
    "    # If no liked products are found, provide a default list of popular seasonal products\n",
    "    if not liked_products:\n",
    "        seasonal_popular = product_df[product_df['season'] == current_season]['id'].value_counts().index.tolist()\n",
    "        total_products = len(seasonal_popular)\n",
    "        decay_factor = 0.9  # Adjust decay factor to control how fast the score decreases\n",
    "        recommendations = [\n",
    "            {\n",
    "                'customer_id': user_id,\n",
    "                'product_id': product,\n",
    "                'rank_score': decay_factor ** idx  # Exponentially decaying score\n",
    "            }\n",
    "            for idx, product in enumerate(seasonal_popular[:top_n])\n",
    "        ]\n",
    "        return recommendations\n",
    "\n",
    "    # Get similar users\n",
    "    similar_users = get_similar_users(user_id, top_n=5)\n",
    "    similar_users_liked_products = []\n",
    "    similar_users_scores = []\n",
    "\n",
    "    if similar_users:\n",
    "        # Get products liked by similar users and their corresponding similarity scores\n",
    "        for similar_user in similar_users:\n",
    "            similarity_score = user_similarity_df.loc[user_id, similar_user]\n",
    "            similar_user_products = customer_df[customer_df['customer_id'] == similar_user]['past_trans'].values[0]\n",
    "            similar_user_products = ast.literal_eval(similar_user_products) if isinstance(similar_user_products, str) else similar_user_products\n",
    "            similar_users_liked_products.extend(similar_user_products)\n",
    "            similar_users_scores.extend([similarity_score] * len(similar_user_products))\n",
    "\n",
    "    # Get products similar to what the user liked\n",
    "    similar_products = similarity_df[similarity_df['product_id'].isin(liked_products)]\n",
    "    similar_products_ids = similar_products['similar_product_id'].tolist()\n",
    "    similar_products_scores = similar_products['distance'].tolist()  # Assuming smaller distance means higher similarity\n",
    "\n",
    "    # Filter recommendations by season\n",
    "    seasonal_products = product_df[product_df['id'].isin(similar_products_ids + similar_users_liked_products) &\n",
    "                                   (product_df['season'] == current_season)]\n",
    "\n",
    "    if seasonal_products.empty:\n",
    "        seasonal_products = product_df[product_df['season'] == current_season].head(top_n)\n",
    "\n",
    "    # Aggregate scores for products\n",
    "    product_scores = {}\n",
    "\n",
    "    # Add scores from similar users' liked products\n",
    "    for product_id, score in zip(similar_users_liked_products, similar_users_scores):\n",
    "        if product_id in seasonal_products['id'].values:\n",
    "            product_scores[product_id] = product_scores.get(product_id, 0) + score\n",
    "\n",
    "    # Add scores from similar products\n",
    "    for product_id, score in zip(similar_products_ids, similar_products_scores):\n",
    "        if product_id in seasonal_products['id'].values:\n",
    "            similarity_score = 1 / (1 + score)  # Using inverse distance as a similarity score\n",
    "            product_scores[product_id] = product_scores.get(product_id, 0) + similarity_score\n",
    "\n",
    "    # Normalize the scores to be between 0 and 1\n",
    "    max_score = max(product_scores.values()) if product_scores else 1\n",
    "    for product_id in product_scores:\n",
    "        product_scores[product_id] /= max_score\n",
    "\n",
    "    # Sort products by their aggregated scores in descending order and select the top N\n",
    "    ranked_products = sorted(product_scores.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "    # Prepare the recommendation list for the user\n",
    "    recommendations = [{'customer_id': user_id, 'product_id': product_id, 'rank_score': rank_score}\n",
    "                       for product_id, rank_score in ranked_products]\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rnPT6-y9YB4t"
   },
   "outputs": [],
   "source": [
    "# Generate recommendations for all customers for each season\n",
    "seasons = ['Spring']\n",
    "\n",
    "for season in seasons:\n",
    "    all_recommendations = []\n",
    "    for user_id in customer_df['customer_id']:\n",
    "        user_recommendations = get_recommendations(user_id, current_season=season, top_n=10)\n",
    "        all_recommendations.extend(user_recommendations)\n",
    "\n",
    "    # Convert all recommendations to DataFrame and save to CSV for the current season\n",
    "    recommendations_df = pd.DataFrame(all_recommendations)\n",
    "    csv_filename = f'recommendations_{season}.csv'\n",
    "    recommendations_df.to_csv(csv_filename, index=False)\n",
    "    print(f\"Recommendations for season '{season}' saved to {csv_filename}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DbMS9iH-YCBT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vwPCUB5pbBP"
   },
   "source": [
    "output for LLM Integration\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
